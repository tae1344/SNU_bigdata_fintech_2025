import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, make_scorer, roc_curve, precision_recall_curve
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
import xgboost as xgb
import lightgbm as lgb
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
import joblib
import json
import copy

# ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
df = pd.read_csv("gss_processed_data.csv")

X = df.drop("target", axis=1)
y = df["target"]

# 4. ê°€ì¤‘ì¹˜ ë¶„ë¦¬
weights = X["weight"]
X = X.drop("weight", axis=1)

# 5. íŠ¹ì„±ë³„ ì „ì²˜ë¦¬
def create_preprocessing_pipeline():
    """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„± - ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€"""
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    imputer = SimpleImputer(strategy='median')
    
    # íŠ¹ì„±ë³„ ì „ì²˜ë¦¬
    preprocessor = ColumnTransformer(
        transformers=[
            ('std', StandardScaler(), ['age', 'yearsmarried', 'education']),
            ('minmax', MinMaxScaler(), ['children'])
        ],
        remainder='passthrough'
    )
    
    return Pipeline([
        ('imputer', imputer),
        ('preprocessor', preprocessor)
    ])

def preprocess_features(X):
    """ê¸°ì¡´ í•¨ìˆ˜ - í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    imputer = SimpleImputer(strategy='median')
    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)
    
    # ìŠ¤ì¼€ì¼ë§
    X_scaled = X_imputed.copy()
    
    # StandardScaler ì ìš© (ì—°ì†í˜• ë³€ìˆ˜)
    std_cols = ['age', 'yearsmarried', 'education']
    std_cols = [col for col in std_cols if col in X_scaled.columns]
    if std_cols:
        scaler = StandardScaler()
        X_scaled[std_cols] = scaler.fit_transform(X_imputed[std_cols])
    
    # MinMaxScaler ì ìš© (ë²”ìœ„ê°€ ì œí•œëœ ë³€ìˆ˜)
    minmax_cols = ['children']
    minmax_cols = [col for col in minmax_cols if col in X_scaled.columns]
    if minmax_cols:
        minmax_scaler = MinMaxScaler()
        X_scaled[minmax_cols] = minmax_scaler.fit_transform(X_imputed[minmax_cols])
    
    return X_scaled

# 6. íŠ¹ì„± ì„¸íŠ¸ë³„ ëª¨ë¸ë§
def create_feature_sets(X):
    # ê¸°ë³¸ íŠ¹ì„± ì„¸íŠ¸
    basic_features = [
        'age', 'children', 'religiousness_5', 'education',
        'occupation_grade6', 'occupation_husb_grade6',
        'gender_male', 'gender_female'
    ]
    
    # ê³ ê¸‰ íŠ¹ì„± ì„¸íŠ¸ (ê²°í˜¼ ì—°ìˆ˜ í¬í•¨)
    advanced_features = basic_features + [
        'yearsmarried', 'yrs_per_age', 'imputed_yearsmarried'
    ]
    
    # ìµœê³ ê¸‰ íŠ¹ì„± ì„¸íŠ¸ (ê²°í˜¼ ë§Œì¡±ë„ í¬í•¨)
    premium_features = advanced_features + [
        'rating_5', 'rate_x_yrs'
    ]
    
    return {
        'basic': [col for col in basic_features if col in X.columns],
        'advanced': [col for col in advanced_features if col in X.columns],
        'premium': [col for col in premium_features if col in X.columns]
    }

# ìµœì  threshold ì°¾ê¸° í•¨ìˆ˜
def safe_find_optimal_threshold(y_true, y_pred_proba, weights=None):
    """ì•ˆì „í•œ ìµœì  threshold ì°¾ê¸° í•¨ìˆ˜"""
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    unique_classes = np.unique(y_true)
    if len(unique_classes) < 2:
        print(f"  âš ï¸ ê²½ê³ : threshold ê³„ì‚° ë¶ˆê°€ - í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ì¡´ì¬")
        return {
            'roc_optimal': 0.5,
            'f1_optimal': 0.5,
            'high_recall': 0.5,
            'thresholds': [0.5],
            'fpr': [0.0],
            'tpr': [1.0],
            'f1_scores': [0.0]
        }
    
    try:
        # ROC ê³¡ì„  ê¸°ë°˜ ìµœì  threshold
        fpr, tpr, thresholds_roc = roc_curve(y_true, y_pred_proba, sample_weight=weights)
        
        # Youden's J statistic (J = TPR - FPR)
        j_scores = tpr - fpr
        optimal_threshold_roc = thresholds_roc[np.argmax(j_scores)]
        
        # F1-score ê¸°ë°˜ ìµœì  threshold
        f1_scores = []
        for threshold in thresholds_roc:
            y_pred_binary = (y_pred_proba >= threshold).astype(int)
            f1 = f1_score(y_true, y_pred_binary, sample_weight=weights, zero_division=0)
            f1_scores.append(f1)
        
        optimal_threshold_f1 = thresholds_roc[np.argmax(f1_scores)]
        
        # ë†’ì€ ì¬í˜„ìœ¨ threshold
        recall_target = 0.8
        threshold_high_recall = thresholds_roc[np.argmin(np.abs(tpr - recall_target))]
        
        return {
            'roc_optimal': optimal_threshold_roc,
            'f1_optimal': optimal_threshold_f1,
            'high_recall': threshold_high_recall,
            'thresholds': thresholds_roc,
            'fpr': fpr,
            'tpr': tpr,
            'f1_scores': f1_scores
        }
        
    except Exception as e:
        print(f"  âŒ Threshold ê³„ì‚° ì˜¤ë¥˜: {e}")
        return {
            'roc_optimal': 0.5,
            'f1_optimal': 0.5,
            'high_recall': 0.5,
            'thresholds': [0.5],
            'fpr': [0.0],
            'tpr': [1.0],
            'f1_scores': [0.0]
        }

def safe_metrics(y_true, y_pred, y_pred_proba, sample_weight=None):
    """ì•ˆì „í•œ ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜"""
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    unique_classes = np.unique(y_true)
    if len(unique_classes) < 2:
        print(f"  âš ï¸ ê²½ê³ : í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ì¡´ì¬í•©ë‹ˆë‹¤. í´ë˜ìŠ¤: {unique_classes}")
        return {
            'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 
            'accuracy': 1.0 if len(unique_classes) == 1 else 0.0,
            'roc_auc': 0.5, 'threshold': 0.5
        }
    
    # ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    unique_preds = np.unique(y_pred)
    if len(unique_preds) < 2:
        print(f"  âš ï¸ ê²½ê³ : ì˜ˆì¸¡ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ì¡´ì¬í•©ë‹ˆë‹¤. ì˜ˆì¸¡: {unique_preds}")
    
    try:
        # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
        f1 = f1_score(y_true, y_pred, sample_weight=sample_weight, zero_division=0)
        precision = precision_score(y_true, y_pred, sample_weight=sample_weight, zero_division=0)
        recall = recall_score(y_true, y_pred, sample_weight=sample_weight, zero_division=0)
        accuracy = accuracy_score(y_true, y_pred, sample_weight=sample_weight)
        
        # ROC-AUC ê³„ì‚° (ì•ˆì „í•˜ê²Œ)
        try:
            roc_auc = roc_auc_score(y_true, y_pred_proba, sample_weight=sample_weight)
        except ValueError:
            print(f"  âš ï¸ ROC-AUC ê³„ì‚° ë¶ˆê°€: í´ë˜ìŠ¤ ë¶„í¬ ë¬¸ì œ")
            roc_auc = 0.5
        
        return {
            'f1': f1, 'precision': precision, 'recall': recall, 
            'accuracy': accuracy, 'roc_auc': roc_auc
        }
        
    except Exception as e:
        print(f"  âŒ ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return {
            'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 
            'accuracy': 0.0, 'roc_auc': 0.5
        }

# ê¸°ì¡´ í•¨ìˆ˜ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•˜ë˜ ë‚´ë¶€ì—ì„œ ì•ˆì „ í•¨ìˆ˜ í˜¸ì¶œ
def find_optimal_threshold(y_true, y_pred_proba, weights=None):
    """ROC ê³¡ì„ ê³¼ PR ê³¡ì„ ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì  threshold ì°¾ê¸° (ì•ˆì „ ë²„ì „)"""
    return safe_find_optimal_threshold(y_true, y_pred_proba, weights)

# SMOTEë¥¼ ì‚¬ìš©í•œ ì˜¤ë²„ìƒ˜í”Œë§
def improved_balance_data(X_train, y_train, w_train):
    """êµì°¨ê²€ì¦ ë‚´ì—ì„œë§Œ SMOTE ì ìš©í•˜ì—¬ ê³¼ì í•© ë°©ì§€"""
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    class_counts = np.bincount(y_train)
    print(f"  ğŸ“Š ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬: {class_counts}")
    
    # ê·¹ë‹¨ì ì¸ ë¶ˆê· í˜• í™•ì¸
    if len(class_counts) < 2 or min(class_counts) < 3:
        print(f"  âš ï¸ ê²½ê³ : í´ë˜ìŠ¤ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. SMOTE ì ìš©í•˜ì§€ ì•ŠìŒ")
        return X_train, y_train, w_train
    
    # SMOTE ì ìš©
    try:
        smote = SMOTE(sampling_strategy=0.3, random_state=42, k_neighbors=min(3, min(class_counts)-1))
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
        
        # ê°€ì¤‘ì¹˜ ë³´ì¡´ ë° ì¡°ì •
        w_train_balanced = np.ones(len(y_train_balanced))
        
        if len(w_train) > 0:
            w_train_balanced[y_train_balanced == 1] = w_train[y_train == 1].mean()
            w_train_balanced[y_train_balanced == 0] = w_train[y_train == 0].mean()
        
        print(f"  ğŸ†• SMOTE ì ìš©: {len(X_train)} â†’ {len(X_train_balanced)}")
        print(f"  ğŸ†• í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train)} â†’ {np.bincount(y_train_balanced)}")
        
        return X_train_balanced, y_train_balanced, w_train_balanced
        
    except Exception as e:
        print(f"  âŒ SMOTE ì ìš© ì˜¤ë¥˜: {e}. ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
        return X_train, y_train, w_train

# 7. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í¬í•¨í•œ K-fold êµì°¨ ê²€ì¦ í•¨ìˆ˜
def train_and_evaluate_model_with_cv_and_tuning_and_threshold(X, y, weights, feature_set_name, feature_cols, n_folds=5):
    print(f"\n=== {feature_set_name.upper()} ëª¨ë¸ (K-Fold CV + í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹) ===")
    
    # íŠ¹ì„± ì„ íƒ
    X_selected = X[feature_cols].copy()
    
    # ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°
    mask = ~X_selected.isnull().any(axis=1)
    X_clean = X_selected[mask]
    y_clean = y[mask]
    weights_clean = weights[mask]
    
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ìƒ˜í”Œ: {len(X_clean)} í–‰, {len(feature_cols)} íŠ¹ì„±")
    
    if len(X_clean) < 1000:
        print("âš ï¸ ìƒ˜í”Œ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŠ¹ì„± ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        return None
    
    # K-fold êµì°¨ ê²€ì¦ ì„¤ì •
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
    param_grids = {
        'RandomForest': {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 7, 10],  # 15 ì œê±°, 7 ì¶”ê°€ë¡œ ê³¼ì í•© ë°©ì§€
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None],
            'class_weight': ['balanced', 'balanced_subsample']
        },
        'XGBoost': {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 6, 9],
            'learning_rate': [0.1, 0.15, 0.2],  # 0.01 ì œê±°, 0.15 ì¶”ê°€ë¡œ ì¼ê´€ì„± í–¥ìƒ
            'subsample': [0.7, 0.8, 0.9],  # ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì •
            'colsample_bytree': [0.7, 0.8, 0.9],  # ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì •
            'reg_alpha': [0.1, 1, 10],  # L1 ì •ê·œí™” ê°•í™”
            'reg_lambda': [0.1, 1, 10]  # L2 ì •ê·œí™” ê°•í™”
        },
    }
    
    # ê¸°ë³¸ ëª¨ë¸ ì •ì˜
    base_models = {
        'RandomForest': RandomForestClassifier(random_state=42),
        'XGBoost': xgb.XGBClassifier(random_state=42, scale_pos_weight=4.6),
    }
    
    # ê° ëª¨ë¸ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° K-fold ê²°ê³¼ ì €ì¥
    cv_results = {}
    best_models = {}
    
    for name, base_model in base_models.items():
        print(f"\n--- {name} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘ ---")
        
        # ğŸ†• íŠ¹ì„± ì„¸íŠ¸ë³„ ì ì‘ì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •
        adaptive_param_grid = param_grids[name].copy()
        
        if feature_set_name == 'premium':
            # Premium ì„¸íŠ¸ì—ì„œ ì •ê·œí™” ê°•í™”
            if name == 'RandomForest':
                adaptive_param_grid['min_samples_split'] = [5, 10, 15]  # ë” ë³´ìˆ˜ì 
                adaptive_param_grid['min_samples_leaf'] = [2, 4, 6]     # ë” ë³´ìˆ˜ì 
            elif name == 'XGBoost':
                adaptive_param_grid['reg_alpha'] = [1, 5, 10]          # L1 ì •ê·œí™” ê°•í™”
                adaptive_param_grid['reg_lambda'] = [1, 5, 10]         # L2 ì •ê·œí™” ê°•í™”
                adaptive_param_grid['subsample'] = [0.6, 0.7, 0.8]    # ë” ë³´ìˆ˜ì 
                adaptive_param_grid['colsample_bytree'] = [0.6, 0.7, 0.8]  # ë” ë³´ìˆ˜ì 
            print(f"  ğŸ†• Premium ì„¸íŠ¸: {name} ì •ê·œí™” ê°•í™” ì ìš©")
        
        elif feature_set_name == 'advanced':
            # Advanced ì„¸íŠ¸ì—ì„œ ì¤‘ê°„ ìˆ˜ì¤€ ì •ê·œí™”
            if name == 'RandomForest':
                adaptive_param_grid['min_samples_split'] = [3, 5, 10]
                adaptive_param_grid['min_samples_leaf'] = [1, 2, 4]
            elif name == 'XGBoost':
                adaptive_param_grid['reg_alpha'] = [0.1, 1, 5]
                adaptive_param_grid['reg_lambda'] = [0.1, 1, 5]
            print(f"  ğŸ†• Advanced ì„¸íŠ¸: {name} ì¤‘ê°„ ìˆ˜ì¤€ ì •ê·œí™” ì ìš©")
        
        else:  # Basic ì„¸íŠ¸
            print(f"  ğŸ†• Basic ì„¸íŠ¸: {name} ê¸°ë³¸ ì •ê·œí™” ìœ ì§€")
        
        # ğŸ†• RandomizedSearchCV ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
        random_search = RandomizedSearchCV(
            base_model, 
            param_distributions=adaptive_param_grid,
            n_iter=20,  # ğŸ†• 20ê°œ ì¡°í•©ë§Œ ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
            cv=skf, 
            scoring='f1',
            n_jobs=-1,
            verbose=1,
            random_state=42  # ğŸ†• ì¬í˜„ì„± ë³´ì¥
        )
        
        # ëª¨ë¸ í›ˆë ¨
        random_search.fit(X_clean, y_clean)
        
        # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥
        print(f"  ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {random_search.best_params_}")
        print(f"  ìµœì  CV ì ìˆ˜: {random_search.best_score_:.4f}")
        
        # ìµœì  ëª¨ë¸ë¡œ K-fold êµì°¨ ê²€ì¦ ìˆ˜í–‰
        best_model = random_search.best_estimator_
        best_models[name] = best_model
        
        # K-fold ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        fold_scores = {
            'f1_scores': [],
            'roc_auc_scores': [],
            'precision_scores': [],
            'recall_scores': [],
            'accuracy_scores': [],
            'optimal_thresholds': [],
            'threshold_metrics': []   
        }
        
        # ê° foldë³„ í›ˆë ¨ ë° í‰ê°€
        for fold, (train_idx, test_idx) in enumerate(skf.split(X_clean, y_clean), 1):
            print(f"  Fold {fold}/{n_folds} ì§„í–‰ ì¤‘...")
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test = X_clean.iloc[train_idx], X_clean.iloc[test_idx]
            y_train, y_test = y_clean.iloc[train_idx], y_clean.iloc[test_idx]
            w_train, w_test = weights_clean.iloc[train_idx], weights_clean.iloc[test_idx]

            # ğŸ†• ì—¬ê¸°ì— SMOTE ì ìš© (í›ˆë ¨ ë°ì´í„°ì—ë§Œ)
            X_train_bal, y_train_bal, w_train_bal = improved_balance_data(
                X_train, y_train, w_train
            )
            
            # ğŸ†• ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„± ë° ì ìš© (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
            preprocessing_pipeline = create_preprocessing_pipeline()
            preprocessing_pipeline.fit(X_train_bal)  # í›ˆë ¨ ë°ì´í„°ë¡œë§Œ íŒŒì´í”„ë¼ì¸ í›ˆë ¨
            
            # í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜
            X_train_processed = preprocessing_pipeline.transform(X_train_bal)
            X_test_processed = preprocessing_pipeline.transform(X_test)
            
            # ğŸ†• ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ê²€ì¦ (ì²« ë²ˆì§¸ foldì—ì„œë§Œ)
            if fold == 1:
                verify_data_leakage_prevention(X_train_bal, X_test, preprocessing_pipeline)
            
            # ğŸ†• ëª¨ë¸ ê¹Šì€ ë³µì‚¬ë¡œ ìƒíƒœ ì˜¤ì—¼ ë°©ì§€
            fold_model = copy.deepcopy(best_model)
            
            # ğŸ†• ì•ˆì „í•œ Early Stopping êµ¬í˜„
            if hasattr(fold_model, 'early_stopping') and isinstance(fold_model, xgb.XGBClassifier):
                fold_model.fit(X_train_processed, y_train_bal, 
                            sample_weight=w_train_bal,
                            eval_set=[(X_test_processed, y_test)],
                            early_stopping_rounds=50,
                            verbose=False)
            else:
                # ğŸ†• ë‹¤ë¥¸ ëª¨ë¸ì€ ì¼ë°˜ì ì¸ í›ˆë ¨
                if hasattr(fold_model, 'sample_weight'):
                    fold_model.fit(X_train_processed, y_train_bal, sample_weight=w_train_bal)
                else:
                    fold_model.fit(X_train_processed, y_train_bal)
            
            # ì˜ˆì¸¡
            y_pred = fold_model.predict(X_test_processed)
            y_pred_proba = fold_model.predict_proba(X_test_processed)[:, 1]

            # ìµœì  threshold ì°¾ê¸°
            threshold_results = safe_find_optimal_threshold(y_test, y_pred_proba, w_test)
            
            # ë‹¤ì–‘í•œ thresholdë¡œ ì„±ëŠ¥ í‰ê°€
            thresholds_to_test = [
                0.5,  # ê¸°ë³¸ threshold
                threshold_results['roc_optimal'],
                threshold_results['f1_optimal'],
                threshold_results['high_recall']
            ]

            threshold_metrics = {}
            for threshold in thresholds_to_test:
                y_pred_threshold = (y_pred_proba >= threshold).astype(int)
                
                # ğŸ†• ì•ˆì „í•œ ë©”íŠ¸ë¦­ ê³„ì‚° ì‚¬ìš©
                metrics = safe_metrics(y_test, y_pred_threshold, y_pred_proba, w_test)
                
                threshold_metrics[f'threshold_{threshold:.3f}'] = {
                    'f1': metrics['f1'],
                    'precision': metrics['precision'],
                    'recall': metrics['recall'],
                    'accuracy': metrics['accuracy']
                }
            
            # ê¸°ë³¸ threshold (0.5)ë¡œ ì„±ëŠ¥ í‰ê°€
            y_pred = (y_pred_proba >= 0.5).astype(int)
            
            # ğŸ†• ì•ˆì „í•œ ë©”íŠ¸ë¦­ ê³„ì‚° ì‚¬ìš©
            metrics = safe_metrics(y_test, y_pred, y_pred_proba, w_test)
            f1 = metrics['f1']
            auc = metrics['roc_auc']
            precision = metrics['precision']
            recall = metrics['recall']
            accuracy = metrics['accuracy']
            
            # ê²°ê³¼ ì €ì¥
            fold_scores['f1_scores'].append(f1)
            fold_scores['roc_auc_scores'].append(auc)
            fold_scores['precision_scores'].append(precision)
            fold_scores['recall_scores'].append(recall)
            fold_scores['accuracy_scores'].append(accuracy)
            fold_scores['optimal_thresholds'].append(threshold_results)
            fold_scores['threshold_metrics'].append(threshold_metrics)
            
            print(f"    Fold {fold} - F1: {f1:.4f}, AUC: {auc:.4f}")
            print(f"      ìµœì  threshold (ROC): {threshold_results['roc_optimal']:.3f}")
            print(f"      ìµœì  threshold (F1): {threshold_results['f1_optimal']:.3f}")
            print(f"      ë†’ì€ ì¬í˜„ìœ¨ threshold: {threshold_results['high_recall']:.3f}")
        
        # K-fold ê²°ê³¼ ìš”ì•½
        cv_results[name] = {
            'best_params': random_search.best_params_,
            'best_cv_score': random_search.best_score_,
            'fold_scores': fold_scores,
            'mean_scores': {
                'f1_score': np.mean(fold_scores['f1_scores']),
                'roc_auc': np.mean(fold_scores['roc_auc_scores']),
                'precision': np.mean(fold_scores['precision_scores']),
                'recall': np.mean(fold_scores['recall_scores']),
                'accuracy': np.mean(fold_scores['accuracy_scores'])
            },
            'std_scores': {
                'f1_score': np.std(fold_scores['f1_scores']),
                'roc_auc': np.std(fold_scores['roc_auc_scores']),
                'precision': np.std(fold_scores['precision_scores']),
                'recall': np.std(fold_scores['recall_scores']),
                'accuracy': np.std(fold_scores['accuracy_scores'])
            },
            'threshold_analysis': {
                'mean_roc_threshold': np.mean([t['roc_optimal'] for t in fold_scores['optimal_thresholds']]),
                'mean_f1_threshold': np.mean([t['f1_optimal'] for t in fold_scores['optimal_thresholds']]),
                'mean_high_recall_threshold': np.mean([t['high_recall'] for t in fold_scores['optimal_thresholds']])
            }
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n  ğŸ¯ {name} ìµœì í™” í›„ K-Fold ê²°ê³¼ ìš”ì•½:")
        print(f"    F1-Score: {cv_results[name]['mean_scores']['f1_score']:.4f} Â± {cv_results[name]['std_scores']['f1_score']:.4f}")
        print(f"    ROC-AUC: {cv_results[name]['mean_scores']['roc_auc']:.4f} Â± {cv_results[name]['std_scores']['roc_auc']:.4f}")
        print(f"    Precision: {cv_results[name]['mean_scores']['precision']:.4f} Â± {cv_results[name]['std_scores']['precision']:.4f}")
        print(f"    Recall: {cv_results[name]['mean_scores']['recall']:.4f} Â± {cv_results[name]['std_scores']['recall']:.4f}")
        print(f"    Accuracy: {cv_results[name]['mean_scores']['accuracy']:.4f} Â± {cv_results[name]['std_scores']['accuracy']:.4f}")
        
         # Threshold ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ì¶”ê°€
        print(f"    ğŸ“Š Threshold ë¶„ì„:")
        print(f"      ROC ìµœì  threshold: {cv_results[name]['threshold_analysis']['mean_roc_threshold']:.3f}")
        print(f"      F1 ìµœì  threshold: {cv_results[name]['threshold_analysis']['mean_f1_threshold']:.3f}")
        print(f"      ë†’ì€ ì¬í˜„ìœ¨ threshold: {cv_results[name]['threshold_analysis']['mean_high_recall_threshold']:.3f}")
        
        # ğŸ†• ëª¨ë¸ ë…ë¦½ì„± ê²€ì¦
        fold_results_for_verification = []
        for i in range(len(fold_scores['f1_scores'])):
            fold_results_for_verification.append({
                'f1': fold_scores['f1_scores'][i],
                'roc_auc': fold_scores['roc_auc_scores'][i]
            })
        verify_model_independence(fold_results_for_verification)
    return cv_results, best_models




# 9. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í¬í•¨)
def main_with_tuning():
    print("ğŸš€ GSS ë°ì´í„° ë¶ˆë¥œ ì˜ˆì¸¡ ëª¨ë¸ë§ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í¬í•¨)")
    
    # íŠ¹ì„± ì„¸íŠ¸ ìƒì„±
    feature_sets = create_feature_sets(X)
    
    # ê° íŠ¹ì„± ì„¸íŠ¸ë³„ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° K-fold êµì°¨ ê²€ì¦ ìˆ˜í–‰
    all_cv_results = {}
    all_best_models = {}
    
    for set_name, feature_cols in feature_sets.items():
        print(f"\n{'='*60}")
        print(f"íŠ¹ì„± ì„¸íŠ¸: {set_name.upper()}")
        print(f"íŠ¹ì„±: {feature_cols}")
        print(f"{'='*60}")
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° K-fold êµì°¨ ê²€ì¦
        cv_results, best_models = train_and_evaluate_model_with_cv_and_tuning_and_threshold(
            X, y, weights, set_name, feature_cols, n_folds=5
        )
        
        if cv_results:
            all_cv_results[set_name] = cv_results
            all_best_models[set_name] = best_models
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*80}")
    print(f"ì „ì²´ ëª¨ë¸ë§ ê²°ê³¼ ìš”ì•½ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ + ì ì‘ì  ìµœì í™” í¬í•¨)")
    print(f"{'='*80}")
    
    for set_name, results in all_cv_results.items():
        print(f"\n {set_name.upper()} íŠ¹ì„± ì„¸íŠ¸:")
        for model_name, cv_result in results.items():
            f1_score = cv_result['mean_scores']['f1_score']
            f1_std = cv_result['std_scores']['f1_score']
            auc_score = cv_result['mean_scores']['roc_auc']
            auc_std = cv_result['std_scores']['roc_auc']
            
            print(f"  {model_name}:")
            print(f"    F1={f1_score:.4f}Â±{f1_std:.4f}, AUC={auc_score:.4f}Â±{auc_std:.4f}")
            print(f"    ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {cv_result['best_params']}")
            
            # ğŸ†• íŠ¹ì„± ì„¸íŠ¸ë³„ ìµœì í™” ì •ë³´ ì¶”ê°€
            if set_name == 'premium':
                print(f"    ğŸ†• Premium ìµœì í™”: ì •ê·œí™” ê°•í™”, ê³¼ì í•© ë°©ì§€")
            elif set_name == 'advanced':
                print(f"    ğŸ†• Advanced ìµœì í™”: ì¤‘ê°„ ìˆ˜ì¤€ ì •ê·œí™”")
            else:
                print(f"    ğŸ†• Basic ìµœì í™”: ê¸°ë³¸ ì •ê·œí™” ìœ ì§€")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
    best_overall = None
    best_overall_score = 0
    best_overall_set = None
    
    for set_name, results in all_cv_results.items():
        for model_name, cv_result in results.items():
            f1_score = cv_result['mean_scores']['f1_score']
            if f1_score > best_overall_score:
                best_overall_score = f1_score
                best_overall = all_best_models[set_name][model_name]
                best_overall_set = f"{set_name}_{model_name}"
    
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_overall_set}")
    print(f"ìµœê³  F1-Score: {best_overall_score:.4f}")
    
    return all_best_models, all_cv_results, best_overall


def check_data_quality(X, y):
    print("=== ë°ì´í„° í’ˆì§ˆ ì²´í¬ ===")
    
    # 1. ìƒ˜í”Œ ìˆ˜ í™•ì¸
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"í´ë˜ìŠ¤ ë¶„í¬: {y.value_counts()}")
    
    # 2. íŠ¹ì„±ë³„ ê²°ì¸¡ê°’ í™•ì¸
    print(f"\nê²°ì¸¡ê°’ í˜„í™©:")
    for col in X.columns:
        missing = X[col].isnull().sum()
        if missing > 0:
            print(f"  {col}: {missing}ê°œ ({missing/len(X)*100:.2f}%)")
    
    # 3. íŠ¹ì„±ë³„ ë¶„ì‚° í™•ì¸
    print(f"\níŠ¹ì„±ë³„ ë¶„ì‚°:")
    for col in X.columns:
        variance = X[col].var()
        print(f"  {col}: {variance:.6f}")
    
    # 4. íŠ¹ì„±ë³„ ë²”ìœ„ í™•ì¸
    print(f"\níŠ¹ì„±ë³„ ë²”ìœ„:")
    for col in X.columns:
        min_val = X[col].min()
        max_val = X[col].max()
        print(f"  {col}: {min_val} ~ {max_val}")
    
    # 5. ì´ìƒì¹˜ í™•ì¸
    print(f"\nì´ìƒì¹˜ í˜„í™© (IQR ê¸°ì¤€):")
    for col in X.columns:
        if X[col].dtype in ['int64', 'float64']:
            Q1 = X[col].quantile(0.25)
            Q3 = X[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = ((X[col] < lower_bound) | (X[col] > upper_bound)).sum()
            print(f"  {col}: {outliers}ê°œ ({outliers/len(X)*100:.2f}%)")

def check_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ í•¨ìˆ˜"""
    try:
        import psutil
        process = psutil.Process()
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / 1024 / 1024
        print(f"  ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.2f} MB")
        return memory_mb
    except ImportError:
        print("  ğŸ“Š psutilì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

def verify_data_leakage_prevention(X_train, X_test, preprocessing_pipeline):
    """ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ê²€ì¦ í•¨ìˆ˜"""
    print(f"  ğŸ” ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ê²€ì¦:")
    
    # í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í†µê³„ ë¹„êµ
    train_stats = X_train.describe()
    test_stats = X_test.describe()
    
    # ìŠ¤ì¼€ì¼ë§ í›„ í†µê³„ í™•ì¸
    X_train_processed = preprocessing_pipeline.transform(X_train)
    X_test_processed = preprocessing_pipeline.transform(X_test)
    
    train_processed_stats = pd.DataFrame(X_train_processed).describe()
    test_processed_stats = pd.DataFrame(X_test_processed).describe()
    
    print(f"    í›ˆë ¨ ë°ì´í„° ì›ë³¸ í†µê³„:")
    print(f"      í‰ê· : {train_stats.mean().mean():.4f}")
    print(f"      í‘œì¤€í¸ì°¨: {train_stats.std().mean():.4f}")
    
    print(f"    í…ŒìŠ¤íŠ¸ ë°ì´í„° ì›ë³¸ í†µê³„:")
    print(f"      í‰ê· : {test_stats.mean().mean():.4f}")
    print(f"      í‘œì¤€í¸ì°¨: {test_stats.std().mean():.4f}")
    
    print(f"    ì „ì²˜ë¦¬ í›„ í›ˆë ¨ ë°ì´í„° í†µê³„:")
    print(f"      í‰ê· : {train_processed_stats.mean().mean():.4f}")
    print(f"      í‘œì¤€í¸ì°¨: {train_processed_stats.std().mean():.4f}")
    
    print(f"    ì „ì²˜ë¦¬ í›„ í…ŒìŠ¤íŠ¸ ë°ì´í„° í†µê³„:")
    print(f"      í‰ê· : {test_processed_stats.mean().mean():.4f}")
    print(f"      í‘œì¤€í¸ì°¨: {test_processed_stats.std().mean():.4f}")
    
    # ë°ì´í„° ëˆ„ìˆ˜ í™•ì¸ (í›ˆë ¨ ë°ì´í„° í†µê³„ê°€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©ë˜ì—ˆëŠ”ì§€)
    print(f"    âœ… ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ í™•ì¸ ì™„ë£Œ: ê° foldì—ì„œ ë…ë¦½ì ì¸ ì „ì²˜ë¦¬ ì ìš©")

def verify_model_independence(fold_results):
    """ëª¨ë¸ ë…ë¦½ì„± ê²€ì¦ í•¨ìˆ˜"""
    print(f"  ğŸ” ëª¨ë¸ ë…ë¦½ì„± ê²€ì¦:")
    
    if len(fold_results) < 2:
        print(f"    âš ï¸ ê²€ì¦ì„ ìœ„í•œ fold ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return
    
    # ê° foldì˜ ê²°ê³¼ê°€ ë…ë¦½ì ì¸ì§€ í™•ì¸
    f1_scores = [result['f1'] for result in fold_results]
    roc_auc_scores = [result['roc_auc'] for result in fold_results]
    
    f1_std = np.std(f1_scores)
    roc_auc_std = np.std(roc_auc_scores)
    
    print(f"    F1-Score í‘œì¤€í¸ì°¨: {f1_std:.4f}")
    print(f"    ROC-AUC í‘œì¤€í¸ì°¨: {roc_auc_std:.4f}")
    
    # í‘œì¤€í¸ì°¨ê°€ ì ì ˆí•œ ë²”ìœ„ì¸ì§€ í™•ì¸
    if f1_std < 0.01:
        print(f"    âš ï¸ F1-Score í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. ëª¨ë¸ ìƒíƒœ ê³µìœ  ê°€ëŠ¥ì„±.")
    elif f1_std > 0.1:
        print(f"    âš ï¸ F1-Score í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤. ëª¨ë¸ ë¶ˆì•ˆì •ì„±.")
    else:
        print(f"    âœ… F1-Score í‘œì¤€í¸ì°¨ê°€ ì ì ˆí•©ë‹ˆë‹¤.")
    
    if roc_auc_std < 0.01:
        print(f"    âš ï¸ ROC-AUC í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. ëª¨ë¸ ìƒíƒœ ê³µìœ  ê°€ëŠ¥ì„±.")
    elif roc_auc_std > 0.1:
        print(f"    âš ï¸ ROC-AUC í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤. ëª¨ë¸ ë¶ˆì•ˆì •ì„±.")
    else:
        print(f"    âœ… ROC-AUC í‘œì¤€í¸ì°¨ê°€ ì ì ˆí•©ë‹ˆë‹¤.")

# 10. ì‹¤í–‰
check_data_quality(X, y)

# ğŸ†• ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
print("\n=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ===")
initial_memory = check_memory_usage()

# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ í¬í•¨ëœ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
best_models, cv_results, best_overall = main_with_tuning()

# ğŸ†• ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
final_memory = check_memory_usage()
if initial_memory and final_memory:
    memory_increase = final_memory - initial_memory
    print(f"  ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€: {memory_increase:.2f} MB")
    if memory_increase > 1000:
        print(f"  âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 1GB ì´ìƒ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"  âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ì ˆí•œ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")


# ìµœê³  ëª¨ë¸ ì €ì¥
joblib.dump(best_overall, f'best_model_best_overall_set.pkl')
print(f"âœ… ìµœê³  ëª¨ë¸ì´ 'best_model_best_overall_set.pkl'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ëª¨ë“  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
# JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
results_for_json = {}
for set_name, results in cv_results.items():
    results_for_json[set_name] = {}
    for model_name, cv_result in results.items():
        results_for_json[set_name][model_name] = {
            'best_params': cv_result['best_params'],
            'best_cv_score': cv_result['best_cv_score'],
            'mean_scores': cv_result['mean_scores'],
            'std_scores': cv_result['std_scores']
        }

with open('modeling_results.json', 'w', encoding='utf-8') as f:
    json.dump(results_for_json, f, ensure_ascii=False, indent=2)

print("âœ… ëª¨ë“  ê²°ê³¼ê°€ 'modeling_results.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


