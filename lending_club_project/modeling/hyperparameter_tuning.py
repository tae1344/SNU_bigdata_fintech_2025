"""
í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ êµ¬í˜„
Grid Search, Random Search, Bayesian Optimizationì„ í†µí•œ ëª¨ë¸ ìµœì í™”
ëª¨ë¸ë§ë³„ ë°ì´í„° í™œìš© ì „ëžµ ì ìš©
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # GUI ì°½ì´ ì—´ë¦¬ì§€ ì•Šë„ë¡ ì„¤ì •
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import (
    GridSearchCV, 
    RandomizedSearchCV,
    StratifiedKFold,
    cross_val_score
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score
import warnings
import sys
import os
from pathlib import Path
import time
from datetime import datetime
import json
import joblib

# XGBoostì™€ LightGBM ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸ XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. XGBoost íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
    print("âœ… LightGBM ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("âš ï¸ LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LightGBM íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

# Bayesian Optimization ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer, Categorical
    BAYESIAN_AVAILABLE = True
    print("âœ… scikit-optimize (Bayesian Optimization) ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    BAYESIAN_AVAILABLE = False
    print("âš ï¸ scikit-optimizeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Bayesian Optimizationì„ ê±´ë„ˆëœë‹ˆë‹¤.")

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.file_paths import (
    SELECTED_FEATURES_PATH,
    SCALED_STANDARD_DATA_PATH,
    SCALED_MINMAX_DATA_PATH,
    NEW_FEATURES_DATA_PATH,
    ensure_directory_exists,
    file_exists
)
from config.settings import settings

warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class HyperparameterTuning:
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í´ëž˜ìŠ¤ - ëª¨ë¸ë§ë³„ ë°ì´í„° í™œìš© ì „ëžµ ì ìš©"""
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.X_train = None
        self.X_val = None
        self.y_train = None
        self.y_val = None
        self.best_models = {}
        self.tuning_results = {}
        
    def get_priority_features(self, priority_level):
        """ìš°ì„ ìˆœìœ„ì— ë”°ë¼ íŠ¹ì„± ì„ íƒ"""
        print(f"ðŸ“Š ìš°ì„ ìˆœìœ„ {priority_level} íŠ¹ì„± ì„ íƒ ì¤‘...")
        
        if not file_exists(SELECTED_FEATURES_PATH):
            print(f"âœ— ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
            return None
            
        selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
        
        if priority_level == 1:
            # ìš°ì„ ìˆœìœ„ 1: 9ê°œ í•µì‹¬ íŠ¹ì„± (ìµœìš°ì„ )
            priority_features = selected_features_df[
                selected_features_df['priority'] == 1
            ]['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„±: {len(priority_features)}ê°œ")
            
        elif priority_level == 2:
            # ìš°ì„ ìˆœìœ„ 2: 17ê°œ íŠ¹ì„± (1 + 2)
            priority_features = selected_features_df[
                selected_features_df['priority'].isin([1, 2])
            ]['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 2 íŠ¹ì„±: {len(priority_features)}ê°œ")
            
        else:  # priority_level == 3
            # ìš°ì„ ìˆœìœ„ 3: 30ê°œ íŠ¹ì„± (ëª¨ë“  ì„ íƒëœ íŠ¹ì„±)
            priority_features = selected_features_df['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„±: {len(priority_features)}ê°œ")
        
        return priority_features
    
    def load_data_for_model(self, model_type):
        """ëª¨ë¸ íƒ€ìž…ì— ë”°ë¼ ì ì ˆí•œ ë°ì´í„° ë¡œë“œ"""
        print(f"ðŸ“‚ {model_type} ëª¨ë¸ìš© ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ëª¨ë¸ë³„ ë°ì´í„° ì „ëžµ ì ìš©
        if model_type == "logistic_regression":
            # ë¡œì§€ìŠ¤í‹± íšŒê·€: StandardScaler + ìš°ì„ ìˆœìœ„ 1
            data_path = SCALED_STANDARD_DATA_PATH
            priority_level = 1
            print("  - StandardScaler ë°ì´í„° ì‚¬ìš© (ì„ í˜• ëª¨ë¸ ìµœì í™”)")
            print("  - ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„± ì‚¬ìš© (í•´ì„ ê°€ëŠ¥ì„± ì¤‘ì‹œ)")
            
        elif model_type == "random_forest":
            # ëžœë¤í¬ë ˆìŠ¤íŠ¸: MinMaxScaler + ìš°ì„ ìˆœìœ„ 1
            data_path = SCALED_MINMAX_DATA_PATH
            priority_level = 1
            print("  - MinMaxScaler ë°ì´í„° ì‚¬ìš© (íŠ¸ë¦¬ ëª¨ë¸ ìµœì í™”)")
            print("  - ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„± ì‚¬ìš© (ì•ˆì •ì„± ì¤‘ì‹œ)")
            
        elif model_type in ["xgboost", "lightgbm"]:
            # XGBoost/LightGBM: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 2
            data_path = NEW_FEATURES_DATA_PATH
            priority_level = 2
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ë³µìž¡í•œ íŒ¨í„´ í•™ìŠµ)")
            print("  - ìš°ì„ ìˆœìœ„ 2 íŠ¹ì„± ì‚¬ìš© (ì„±ëŠ¥ê³¼ í•´ì„ì˜ ê· í˜•)")
            
        else:  # ensemble
            # ì•™ìƒë¸”: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 3
            data_path = NEW_FEATURES_DATA_PATH
            priority_level = 3
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ìµœëŒ€ ì„±ëŠ¥)")
            print("  - ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„± ì‚¬ìš© (ëª¨ë“  ì„ íƒ íŠ¹ì„±)")
        
        # ë°ì´í„° íŒŒì¼ ì¡´ìž¬ í™•ì¸
        if not file_exists(data_path):
            print(f"âœ— ë°ì´í„° íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_path}")
            print("ë¨¼ì € feature_engineering ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        df['loan_status_binary'] = df['loan_status'].apply(
            lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
        )
        
        # ìš°ì„ ìˆœìœ„ë³„ íŠ¹ì„± ì„ íƒ
        priority_features = self.get_priority_features(priority_level)
        if priority_features is None:
            return None
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± í•„í„°ë§
        available_features = [f for f in priority_features if f in df.columns]
        print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
        
        X = df[available_features]
        y = df['loan_status_binary']
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        total_missing = X.isnull().sum().sum()
        if total_missing > 0:
            print(f"âš ï¸ ê²½ê³ : {total_missing}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("   feature_engineering_step2_scaling.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            return None
        else:
            print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
        
        return X, y, available_features
    
    def load_data(self):
        """ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
        print("ðŸ“‚ ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            # ì„ íƒëœ íŠ¹ì„± ë¡œë“œ
            if not file_exists(SELECTED_FEATURES_PATH):
                print(f"âœ— ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
                print("ë¨¼ì € feature_selection_analysis.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                return None
                
            selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
            selected_features = selected_features_df['selected_feature'].tolist()
            
            # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ë¡œë“œ
            if not file_exists(SCALED_STANDARD_DATA_PATH):
                print(f"âœ— ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SCALED_STANDARD_DATA_PATH}")
                print("ë¨¼ì € feature_engineering_step2_scaling.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                return None
                
            df = pd.read_csv(SCALED_STANDARD_DATA_PATH)
            
            # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
            df['loan_status_binary'] = df['loan_status'].apply(
                lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
            )
            
            # ì„ íƒëœ íŠ¹ì„±ë§Œ ì‚¬ìš©
            available_features = [f for f in selected_features if f in df.columns]
            print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
            
            X = df[available_features]
            y = df['loan_status_binary']
            
            # ê²°ì¸¡ì¹˜ í™•ì¸
            total_missing = X.isnull().sum().sum()
            if total_missing > 0:
                print(f"âš ï¸ ê²½ê³ : {total_missing}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print("   feature_engineering_step2_scaling.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                return None
            else:
                print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
            
            return X, y, available_features
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def train_validation_split(self, X, y, train_size=0.8, stratify=True):
        """Train/Validation Split"""
        print(f"ðŸ”„ Train/Validation Split ì§„í–‰ ì¤‘...")
        print(f"   í›ˆë ¨: {train_size:.1%}, ê²€ì¦: {1-train_size:.1%}")
        
        try:
            if stratify:
                from sklearn.model_selection import train_test_split
                X_train, X_val, y_train, y_val = train_test_split(
                    X, y, 
                    test_size=1-train_size, 
                    random_state=self.random_state,
                    stratify=y
                )
            else:
                from sklearn.model_selection import train_test_split
                X_train, X_val, y_train, y_val = train_test_split(
                    X, y, 
                    test_size=1-train_size, 
                    random_state=self.random_state
                )
            
            self.X_train = X_train
            self.X_val = X_val
            self.y_train = y_train
            self.y_val = y_val
            
            print(f"âœ“ ë¶„í•  ì™„ë£Œ")
            print(f"   í›ˆë ¨ ë°ì´í„°: {len(X_train):,}ê°œ")
            print(f"   ê²€ì¦ ë°ì´í„°: {len(X_val):,}ê°œ")
            
            return X_train, X_val, y_train, y_val
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¶„í•  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None, None, None
    
    def define_hyperparameter_grids(self):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜"""
        print("ðŸ“‹ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ ì¤‘...")
        
        param_grids = {}
        
        # 1. Logistic Regression
        param_grids['LogisticRegression'] = {
            'C': [0.001, 0.01, 0.1, 1, 10, 100],
            'penalty': ['l1', 'l2'],
            'solver': ['liblinear', 'saga'],
            'max_iter': [1000, 2000],
            'class_weight': [None, 'balanced']
        }
        
        # 2. Random Forest
        param_grids['RandomForest'] = {
            'n_estimators': [50, 100, 200, 300],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None],
            'class_weight': [None, 'balanced', 'balanced_subsample']
        }
        
        # 3. XGBoost (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if XGBOOST_AVAILABLE:
            param_grids['XGBoost'] = {
                'n_estimators': [100, 200, 300],
                'max_depth': [3, 6, 9],
                'learning_rate': [0.01, 0.1, 0.2],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0],
                'reg_alpha': [0, 0.1, 1],
                'reg_lambda': [0, 0.1, 1]
            }
        
        # 4. LightGBM (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        # if LIGHTGBM_AVAILABLE:
        #     param_grids['LightGBM'] = {
        #         'n_estimators': [100, 200, 300],
        #         'max_depth': [3, 6, 9],
        #         'learning_rate': [0.01, 0.1, 0.2],
        #         'subsample': [0.8, 0.9, 1.0],
        #         'colsample_bytree': [0.8, 0.9, 1.0],
        #         'reg_alpha': [0, 0.1, 1],
        #         'reg_lambda': [0, 0.1, 1],
        #         'min_child_samples': [10, 20, 30],
        #         'min_split_gain': [0.0, 0.01, 0.05],
        #         'verbose': [-1]
        #     }
        
        print(f"âœ“ {len(param_grids)}ê°œ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ ì™„ë£Œ")
        return param_grids
    
    def define_random_search_params(self):
        """Random Search íŒŒë¼ë¯¸í„° ì •ì˜"""
        print("ðŸ“‹ Random Search íŒŒë¼ë¯¸í„° ì •ì˜ ì¤‘...")
        
        random_params = {}
        
        # 1. Logistic Regression
        random_params['LogisticRegression'] = {
            'C': [0.001, 0.01, 0.1, 1, 10, 100],
            'penalty': ['l1', 'l2'],
            'solver': ['liblinear', 'saga'],
            'max_iter': [1000, 2000],
            'class_weight': [None, 'balanced']
        }
        
        # 2. Random Forest
        random_params['RandomForest'] = {
            'n_estimators': [50, 100, 200, 300, 400],
            'max_depth': [None, 5, 10, 15, 20, 25, 30],
            'min_samples_split': [2, 5, 10, 15],
            'min_samples_leaf': [1, 2, 4, 6],
            'max_features': ['sqrt', 'log2', None],
            'class_weight': [None, 'balanced', 'balanced_subsample']
        }
        
        # 3. XGBoost
        if XGBOOST_AVAILABLE:
            random_params['XGBoost'] = {
                'n_estimators': [100, 200, 300, 400],
                'max_depth': [3, 6, 9, 12],
                'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
                'subsample': [0.7, 0.8, 0.9, 1.0],
                'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
                'reg_alpha': [0, 0.1, 0.5, 1],
                'reg_lambda': [0, 0.1, 0.5, 1]
            }
        
        # 4. LightGBM
        # if LIGHTGBM_AVAILABLE:
        #     random_params['LightGBM'] = {
        #         'n_estimators': [100, 200, 300, 400],
        #         'max_depth': [3, 6, 9, 12],
        #         'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
        #         'subsample': [0.7, 0.8, 0.9, 1.0],
        #         'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        #         'reg_alpha': [0, 0.1, 0.5, 1],
        #         'reg_lambda': [0, 0.1, 0.5, 1],
        #         'min_child_samples': [10, 20, 30, 50],
        #         'min_split_gain': [0.0, 0.01, 0.05, 0.1],
        #         'verbose': [-1]
        #     }
        
        print(f"âœ“ {len(random_params)}ê°œ ëª¨ë¸ì˜ Random Search íŒŒë¼ë¯¸í„° ì •ì˜ ì™„ë£Œ")
        return random_params
    
    def define_bayesian_search_spaces(self):
        """Bayesian Optimization ê²€ìƒ‰ ê³µê°„ ì •ì˜"""
        print("ðŸ“‹ Bayesian Optimization ê²€ìƒ‰ ê³µê°„ ì •ì˜ ì¤‘...")
        
        search_spaces = {}
        
        # 1. Logistic Regression
        search_spaces['LogisticRegression'] = {
            'C': Real(1e-3, 1e2, prior='log-uniform'),
            'penalty': Categorical(['l1', 'l2']),
            'solver': Categorical(['liblinear', 'saga']),
            'max_iter': Integer(1000, 3000),
            'class_weight': Categorical([None, 'balanced'])
        }
        
        # 2. Random Forest
        search_spaces['RandomForest'] = {
            'n_estimators': Integer(50, 500),
            'max_depth': Integer(5, 50),
            'min_samples_split': Integer(2, 20),
            'min_samples_leaf': Integer(1, 10),
            'max_features': Categorical(['sqrt', 'log2', None]),
            'class_weight': Categorical([None, 'balanced', 'balanced_subsample'])
        }
        
        # 3. XGBoost
        if XGBOOST_AVAILABLE:
            search_spaces['XGBoost'] = {
                'n_estimators': Integer(100, 500),
                'max_depth': Integer(3, 15),
                'learning_rate': Real(0.01, 0.3, prior='log-uniform'),
                'subsample': Real(0.7, 1.0),
                'colsample_bytree': Real(0.7, 1.0),
                'reg_alpha': Real(0, 2),
                'reg_lambda': Real(0, 2)
            }
        
        # 4. LightGBM
        # if LIGHTGBM_AVAILABLE:
        #     search_spaces['LightGBM'] = {
        #         'n_estimators': Integer(100, 500),
        #         'max_depth': Integer(3, 15),
        #         'learning_rate': Real(0.01, 0.3, prior='log-uniform'),
        #         'subsample': Real(0.7, 1.0),
        #         'colsample_bytree': Real(0.7, 1.0),
        #         'reg_alpha': Real(0, 2),
        #         'reg_lambda': Real(0, 2),
        #         'min_child_samples': Integer(10, 50),
        #         'min_split_gain': Real(0.0, 0.1),
        #         'verbose': Categorical([-1])
        #     }
        
        print(f"âœ“ {len(search_spaces)}ê°œ ëª¨ë¸ì˜ Bayesian Optimization ê²€ìƒ‰ ê³µê°„ ì •ì˜ ì™„ë£Œ")
        return search_spaces
    
    def grid_search_tuning(self, model_name, model, param_grid, cv=5, scoring='roc_auc'):
        """Grid Search íŠœë‹"""
        print(f"\nðŸ” {model_name} Grid Search íŠœë‹ ì‹œìž‘...")
        
        try:
            # Grid Search ìˆ˜í–‰
            grid_search = GridSearchCV(
                estimator=model,
                param_grid=param_grid,
                cv=cv,
                scoring=scoring,
                n_jobs=-1,
                verbose=1
            )
            
            start_time = time.time()
            grid_search.fit(self.X_train, self.y_train)
            tuning_time = time.time() - start_time
            
            # ê²°ê³¼ ì €ìž¥
            best_params = grid_search.best_params_
            best_score = grid_search.best_score_
            cv_results = grid_search.cv_results_
            
            # ê²€ì¦ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ í‰ê°€
            best_model = grid_search.best_estimator_
            val_score = grid_search.score(self.X_val, self.y_val)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"âœ“ Grid Search ì™„ë£Œ (ì†Œìš”ì‹œê°„: {tuning_time:.2f}ì´ˆ)")
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
            print(f"   CV ìµœê³  ì ìˆ˜: {best_score:.4f}")
            print(f"   ê²€ì¦ ì ìˆ˜: {val_score:.4f}")
            
            # ê²°ê³¼ ì €ìž¥ (ê³ ìœ  í‚¤ ì‚¬ìš©)
            result_key = f"{model_name}_GridSearch"
            result = {
                'model_name': model_name,
                'tuning_method': 'Grid Search',
                'best_params': best_params,
                'best_cv_score': best_score,
                'val_score': val_score,
                'tuning_time': tuning_time,
                'cv_results': cv_results,
                'best_model': best_model
            }
            
            self.best_models[result_key] = best_model
            self.tuning_results[result_key] = result
            
            return result
            
        except Exception as e:
            print(f"âŒ Grid Search íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def random_search_tuning(self, model_name, model, param_distributions, n_iter=50, cv=5, scoring='roc_auc'):
        """Random Search íŠœë‹"""
        print(f"\nðŸ” {model_name} Random Search íŠœë‹ ì‹œìž‘...")
        
        try:
            # Random Search ìˆ˜í–‰
            random_search = RandomizedSearchCV(
                estimator=model,
                param_distributions=param_distributions,
                n_iter=n_iter,
                cv=cv,
                scoring=scoring,
                n_jobs=-1,
                verbose=1,
                random_state=self.random_state
            )
            
            start_time = time.time()
            random_search.fit(self.X_train, self.y_train)
            tuning_time = time.time() - start_time
            
            # ê²°ê³¼ ì €ìž¥
            best_params = random_search.best_params_
            best_score = random_search.best_score_
            cv_results = random_search.cv_results_
            
            # ê²€ì¦ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ í‰ê°€
            best_model = random_search.best_estimator_
            val_score = random_search.score(self.X_val, self.y_val)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"âœ“ Random Search ì™„ë£Œ (ì†Œìš”ì‹œê°„: {tuning_time:.2f}ì´ˆ)")
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
            print(f"   CV ìµœê³  ì ìˆ˜: {best_score:.4f}")
            print(f"   ê²€ì¦ ì ìˆ˜: {val_score:.4f}")
            
            # ê²°ê³¼ ì €ìž¥ (ê³ ìœ  í‚¤ ì‚¬ìš©)
            result_key = f"{model_name}_RandomSearch"
            result = {
                'model_name': model_name,
                'tuning_method': 'Random Search',
                'best_params': best_params,
                'best_cv_score': best_score,
                'val_score': val_score,
                'tuning_time': tuning_time,
                'cv_results': cv_results,
                'best_model': best_model,
                'n_iter': n_iter
            }
            
            self.best_models[result_key] = best_model
            self.tuning_results[result_key] = result
            
            return result
            
        except Exception as e:
            print(f"âŒ Random Search íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def bayesian_search_tuning(self, model_name, model, search_space, n_iter=50, cv=5, scoring='roc_auc'):
        """Bayesian Optimization íŠœë‹"""
        print(f"\nðŸ” {model_name} Bayesian Optimization íŠœë‹ ì‹œìž‘...")
        
        try:
            # Bayesian Search ìˆ˜í–‰
            bayes_search = BayesSearchCV(
                estimator=model,
                search_spaces=search_space,
                n_iter=n_iter,
                cv=cv,
                scoring=scoring,
                n_jobs=-1,
                verbose=1,
                random_state=self.random_state
            )
            
            start_time = time.time()
            bayes_search.fit(self.X_train, self.y_train)
            tuning_time = time.time() - start_time
            
            # ê²°ê³¼ ì €ìž¥
            best_params = bayes_search.best_params_
            best_score = bayes_search.best_score_
            cv_results = bayes_search.cv_results_
            
            # ê²€ì¦ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ í‰ê°€
            best_model = bayes_search.best_estimator_
            val_score = bayes_search.score(self.X_val, self.y_val)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"âœ“ Bayesian Optimization ì™„ë£Œ (ì†Œìš”ì‹œê°„: {tuning_time:.2f}ì´ˆ)")
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
            print(f"   CV ìµœê³  ì ìˆ˜: {best_score:.4f}")
            print(f"   ê²€ì¦ ì ìˆ˜: {val_score:.4f}")
            
            # ê²°ê³¼ ì €ìž¥ (ê³ ìœ  í‚¤ ì‚¬ìš©)
            result_key = f"{model_name}_BayesianSearch"
            result = {
                'model_name': model_name,
                'tuning_method': 'Bayesian Search',
                'best_params': best_params,
                'best_cv_score': best_score,
                'val_score': val_score,
                'tuning_time': tuning_time,
                'cv_results': cv_results,
                'best_model': best_model,
                'n_iter': n_iter
            }
            
            self.best_models[result_key] = best_model
            self.tuning_results[result_key] = result
            
            return result
            
        except Exception as e:
            print(f"âŒ Bayesian Optimization íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def compare_tuning_methods(self, model_name):
        """íŠœë‹ ë°©ë²• ë¹„êµ"""
        print(f"\nðŸ“Š {model_name} íŠœë‹ ë°©ë²• ë¹„êµ")
        print("-" * 50)
        
        methods = ['GridSearch', 'RandomSearch', 'BayesianSearch']
        
        results = {}
        for method in methods:
            key = f"{model_name}_{method}"
            if key in self.tuning_results:
                results[method] = self.tuning_results[key]
        
        if len(results) > 1:
            print(f"{'ë°©ë²•':<15} {'CVì ìˆ˜':<10} {'ê²€ì¦ì ìˆ˜':<10} {'ì‹œê°„(ì´ˆ)':<10}")
            print("-" * 50)
            
            for method, result in results.items():
                print(f"{method:<15} {result['best_cv_score']:<10.4f} {result['val_score']:<10.4f} {result['tuning_time']:<10.2f}")
            
            # ìµœê³  ì„±ëŠ¥ ë°©ë²• ì°¾ê¸°
            best_method = max(results.keys(), key=lambda x: results[x]['val_score'])
            print(f"\nðŸ† ìµœê³  ì„±ëŠ¥: {best_method} (ê²€ì¦ ì ìˆ˜: {results[best_method]['val_score']:.4f})")
        else:
            print("ë¹„êµí•  ìˆ˜ ìžˆëŠ” íŠœë‹ ë°©ë²•ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    
    def perform_hyperparameter_tuning(self):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìˆ˜í–‰"""
        print("ðŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œìž‘")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            data_result = self.load_data()
            if data_result is None:
                print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                return
            
            X, y = data_result
            
            # Train/Validation Split
            split_result = self.train_validation_split(X, y)
            if split_result[0] is None:
                print("âŒ ë°ì´í„° ë¶„í•  ì‹¤íŒ¨")
                return
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
            param_grids = self.define_hyperparameter_grids()
            random_params = self.define_random_search_params()
            search_spaces = self.define_bayesian_search_spaces()
            
            # ëª¨ë¸ ì •ì˜
            models = {
                'LogisticRegression': LogisticRegression(random_state=self.random_state),
                'RandomForest': RandomForestClassifier(random_state=self.random_state)
            }
            
            if XGBOOST_AVAILABLE:
                models['XGBoost'] = xgb.XGBClassifier(random_state=self.random_state)
            
            # if LIGHTGBM_AVAILABLE:
            #     models['LightGBM'] = lgb.LGBMClassifier(
            #         random_state=self.random_state,
            #         verbose=-1,  # ê²½ê³  ë©”ì‹œì§€ ì–µì œ
            #         force_col_wise=True  # ì»¬ëŸ¼ë³„ ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í–¥ìƒ
            #     )
            
            # ê° ëª¨ë¸ì— ëŒ€í•´ íŠœë‹ ìˆ˜í–‰
            for model_name, model in models.items():
                print(f"\n{'='*60}")
                print(f"ðŸ“Š {model_name} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
                print(f"{'='*60}")
                
                # Grid Search
                if model_name in param_grids:
                    self.grid_search_tuning(model_name, model, param_grids[model_name])
                
                # Random Search
                if model_name in random_params:
                    self.random_search_tuning(model_name, model, random_params[model_name])
                
                # Bayesian Search
                if model_name in search_spaces:
                    self.bayesian_search_tuning(model_name, model, search_spaces[model_name])
                
                # íŠœë‹ ë°©ë²• ë¹„êµ
                self.compare_tuning_methods(model_name)
            
            # ê²°ê³¼ ìš”ì•½
            self.generate_tuning_report()
            
            print("\nâœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def generate_tuning_report(self):
        """íŠœë‹ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        print("\nðŸ“ íŠœë‹ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        try:
            # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
            report_lines = []
            report_lines.append("=" * 80)
            report_lines.append("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ ë³´ê³ ì„œ")
            report_lines.append("=" * 80)
            report_lines.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report_lines.append("")
            
            # ë°ì´í„° ì •ë³´
            report_lines.append("ðŸ“Š ë°ì´í„° ì •ë³´")
            report_lines.append("-" * 40)
            report_lines.append(f"í›ˆë ¨ ë°ì´í„°: {len(self.X_train):,}ê°œ")
            report_lines.append(f"ê²€ì¦ ë°ì´í„°: {len(self.X_val):,}ê°œ")
            report_lines.append(f"íŠ¹ì„± ìˆ˜: {self.X_train.shape[1]}ê°œ")
            report_lines.append("")
            
            # íŠœë‹ ê²°ê³¼ ìš”ì•½
            report_lines.append("ðŸ† íŠœë‹ ê²°ê³¼ ìš”ì•½")
            report_lines.append("-" * 40)
            
            # í…Œì´ë¸” í—¤ë”
            header = f"{'ëª¨ë¸ëª…':<20} {'íŠœë‹ë°©ë²•':<15} {'CVì ìˆ˜':<10} {'ê²€ì¦ì ìˆ˜':<10} {'íŠœë‹ì‹œê°„':<10}"
            report_lines.append(header)
            report_lines.append("-" * len(header))
            
            # ê° ëª¨ë¸ ê²°ê³¼
            for result_key, result in self.tuning_results.items():
                line = f"{result['model_name']:<20} {result['tuning_method']:<15} {result['best_cv_score']:<10.4f} {result['val_score']:<10.4f} {result['tuning_time']:<10.2f}"
                report_lines.append(line)
            
            report_lines.append("")
            
            # ìƒì„¸ ê²°ê³¼
            report_lines.append("ðŸ“‹ ìƒì„¸ íŠœë‹ ê²°ê³¼")
            report_lines.append("-" * 40)
            
            for result_key, result in self.tuning_results.items():
                report_lines.append(f"\n{result['model_name']} ({result['tuning_method']}):")
                report_lines.append(f"  ìµœì  íŒŒë¼ë¯¸í„°: {result['best_params']}")
                report_lines.append(f"  CV ìµœê³  ì ìˆ˜: {result['best_cv_score']:.4f}")
                report_lines.append(f"  ê²€ì¦ ì ìˆ˜: {result['val_score']:.4f}")
                report_lines.append(f"  íŠœë‹ ì‹œê°„: {result['tuning_time']:.2f}ì´ˆ")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
            if self.tuning_results:
                best_result_key = max(self.tuning_results.keys(), 
                                     key=lambda x: self.tuning_results[x]['val_score'])
                best_result = self.tuning_results[best_result_key]
                
                report_lines.append(f"\nðŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_result['model_name']} ({best_result['tuning_method']})")
                report_lines.append(f"  ê²€ì¦ ì ìˆ˜: {best_result['val_score']:.4f}")
                report_lines.append(f"  ìµœì  íŒŒë¼ë¯¸í„°: {best_result['best_params']}")
            
            # ë³´ê³ ì„œ ì €ìž¥
            report_content = "\n".join(report_lines)
            
            output_path = Path(__file__).parent.parent / "reports" / "hyperparameter_tuning_report.txt"
            ensure_directory_exists(output_path.parent)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"âœ“ íŠœë‹ ë³´ê³ ì„œ ì €ìž¥ ì™„ë£Œ: {output_path}")
            
            return report_content
            
        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def save_best_models(self):
        """ìµœì  ëª¨ë¸ ì €ìž¥"""
        print("\nðŸ’¾ ìµœì  ëª¨ë¸ ì €ìž¥ ì¤‘...")
        
        try:
            models_dir = Path(__file__).parent.parent / "models"
            ensure_directory_exists(models_dir)
            
            for result_key, model in self.best_models.items():
                model_path = models_dir / f"{result_key.lower()}.pkl"
                joblib.dump(model, model_path)
                print(f"  âœ“ {result_key}: {model_path}")
            
            print("âœ“ ìµœì  ëª¨ë¸ ì €ìž¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ìž¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ðŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œìž‘")
    
    try:
        # íŠœë‹ í´ëž˜ìŠ¤ ì´ˆê¸°í™”
        tuner = HyperparameterTuning(random_state=42)
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìˆ˜í–‰
        tuner.perform_hyperparameter_tuning()
        
        # ìµœì  ëª¨ë¸ ì €ìž¥
        tuner.save_best_models()
        
        print("\nâœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main() 