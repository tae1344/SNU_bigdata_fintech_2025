"""
ëª¨ë¸ë³„ ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤
ê° ëª¨ë¸ì— ìµœì í™”ëœ ë°ì´í„°ë¥¼ ì œê³µ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import warnings
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.file_paths import (
    SELECTED_FEATURES_PATH,
    SCALED_STANDARD_DATA_PATH,
    SCALED_MINMAX_DATA_PATH,
    VALIDATION_SCALED_STANDARD_DATA_PATH,
    VALIDATION_SCALED_MINMAX_DATA_PATH,
    NEW_FEATURES_DATA_PATH,
    ensure_directory_exists,
    file_exists
)
from config.settings import settings

warnings.filterwarnings('ignore')

class ModelDataLoader:
    """ëª¨ë¸ë³„ ìµœì í™”ëœ ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤"""
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        
    def get_priority_features(self, priority_level):
        """ìš°ì„ ìˆœìœ„ì— ë”°ë¼ íŠ¹ì„± ì„ íƒ"""
        print(f"ğŸ“Š ìš°ì„ ìˆœìœ„ {priority_level} íŠ¹ì„± ì„ íƒ ì¤‘...")
        
        if not file_exists(SELECTED_FEATURES_PATH):
            print(f"âš ï¸ ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
            print("ê¸°ë³¸ íŠ¹ì„± ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            
            # ê¸°ë³¸ íŠ¹ì„± ëª©ë¡ (ìš°ì„ ìˆœìœ„ë³„)
            basic_features = {
                1: [  # ìš°ì„ ìˆœìœ„ 1: í•µì‹¬ íŠ¹ì„± 9ê°œ
                    'loan_amnt', 'int_rate', 'installment', 'dti', 'term_months',
                    'fico_avg', 'delinq_2yrs', 'inq_last_6mths', 'revol_util'
                ],
                2: [  # ìš°ì„ ìˆœìœ„ 2: í•µì‹¬ + ì¶”ê°€ íŠ¹ì„± 17ê°œ
                    'loan_amnt', 'int_rate', 'installment', 'dti', 'term_months',
                    'fico_avg', 'delinq_2yrs', 'inq_last_6mths', 'revol_util',
                    'open_acc', 'pub_rec', 'revol_bal', 'total_acc',
                    'annual_inc', 'emp_length_numeric', 'purpose', 'home_ownership'
                ],
                3: [  # ìš°ì„ ìˆœìœ„ 3: ëª¨ë“  ì£¼ìš” íŠ¹ì„± 30ê°œ
                    'loan_amnt', 'int_rate', 'installment', 'dti', 'term_months',
                    'fico_avg', 'delinq_2yrs', 'inq_last_6mths', 'revol_util',
                    'open_acc', 'pub_rec', 'revol_bal', 'total_acc',
                    'annual_inc', 'emp_length_numeric', 'purpose', 'home_ownership',
                    'fico_range_low', 'fico_range_high', 'sub_grade_ordinal', 'grade_numeric',
                    'mths_since_last_delinq', 'mths_since_last_record',
                    'has_delinquency', 'has_serious_delinquency', 'delinquency_severity',
                    'credit_util_risk', 'purpose_risk', 'loan_to_income_ratio',
                    'annual_return_rate', 'credit_history_months'
                ]
            }
            
            priority_features = basic_features.get(priority_level, basic_features[1])
            print(f"âœ“ ê¸°ë³¸ ìš°ì„ ìˆœìœ„ {priority_level} íŠ¹ì„±: {len(priority_features)}ê°œ")
            return priority_features
            
        selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
        
        if priority_level == 1:
            # ìš°ì„ ìˆœìœ„ 1: 9ê°œ í•µì‹¬ íŠ¹ì„± (ìµœìš°ì„ )
            priority_features = selected_features_df[
                selected_features_df['priority'] == 1
            ]['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„±: {len(priority_features)}ê°œ")
            
        elif priority_level == 2:
            # ìš°ì„ ìˆœìœ„ 2: 17ê°œ íŠ¹ì„± (1 + 2)
            priority_features = selected_features_df[
                selected_features_df['priority'].isin([1, 2])
            ]['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 2 íŠ¹ì„±: {len(priority_features)}ê°œ")
            
        else:  # priority_level == 3
            # ìš°ì„ ìˆœìœ„ 3: 30ê°œ íŠ¹ì„± (ëª¨ë“  ì„ íƒëœ íŠ¹ì„±)
            priority_features = selected_features_df['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„±: {len(priority_features)}ê°œ")
        
        return priority_features
    
    def load_data_for_model(self, model_type):
        """ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ë°ì´í„° ë¡œë“œ (ì „ì²˜ë¦¬ëœ ë°ì´í„° ìš°ì„  ì‚¬ìš©)"""
        print(f"ğŸ“‚ {model_type} ëª¨ë¸ìš© ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸ (ìš°ì„  ì‚¬ìš©)
        preprocessed_dir = Path(__file__).parent / "preprocessed_data"
        if preprocessed_dir.exists():
            # SMOTEë¡œ ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸
            train_file = preprocessed_dir / "train_balanced_smote.csv"
            val_file = preprocessed_dir / "val_balanced_smote.csv"
            
            if train_file.exists() and val_file.exists():
                print("ğŸ“¥ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš© (SMOTE ì ìš©)")
                
                # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
                df_train = pd.read_csv(train_file)
                df_val = pd.read_csv(val_file)
                
                # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬
                y_train = df_train['loan_status_binary']
                y_val = df_val['loan_status_binary']
                
                # íŠ¹ì„± ë³€ìˆ˜ ë¶„ë¦¬
                X_train = df_train.drop('loan_status_binary', axis=1)
                X_val = df_val.drop('loan_status_binary', axis=1)
                
                print(f"âœ“ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
                print(f"  - ê²€ì¦ ë°ì´í„°: {X_val.shape[0]}ê°œ")
                print(f"  - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ")
                print(f"  - í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì •: SMOTE ì ìš©")
                
                return X_train, X_val, y_train, y_val, X_train.columns.tolist()
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        print("ğŸ“¥ ì›ë³¸ ë°ì´í„° ì‚¬ìš© (ì „ì²˜ë¦¬ëœ ë°ì´í„° ì—†ìŒ)")
        
        # ëª¨ë¸ë³„ ë°ì´í„° ì „ëµ ì ìš©
        if model_type == "logistic_regression":
            # ë¡œì§€ìŠ¤í‹± íšŒê·€: StandardScaler + ìš°ì„ ìˆœìœ„ 1
            train_data_path = SCALED_STANDARD_DATA_PATH
            validation_data_path = VALIDATION_SCALED_STANDARD_DATA_PATH
            priority_level = 1
            print("  - StandardScaler ë°ì´í„° ì‚¬ìš© (ì„ í˜• ëª¨ë¸ ìµœì í™”)")
            print("  - ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„± ì‚¬ìš© (í•´ì„ ê°€ëŠ¥ì„± ì¤‘ì‹œ)")
            
        elif model_type == "random_forest":
            # ëœë¤í¬ë ˆìŠ¤íŠ¸: MinMaxScaler + ìš°ì„ ìˆœìœ„ 1
            train_data_path = SCALED_MINMAX_DATA_PATH
            validation_data_path = VALIDATION_SCALED_MINMAX_DATA_PATH
            priority_level = 1
            print("  - MinMaxScaler ë°ì´í„° ì‚¬ìš© (íŠ¸ë¦¬ ëª¨ë¸ ìµœì í™”)")
            print("  - ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„± ì‚¬ìš© (ì•ˆì •ì„± ì¤‘ì‹œ)")
            
        elif model_type in ["xgboost", "lightgbm"]:
            # XGBoost/LightGBM: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 2
            # ìƒˆë¡œìš´ íŠ¹ì„± ë°ì´í„°ëŠ” ê²€ì¦ìš©ì´ ì—†ìœ¼ë¯€ë¡œ í›ˆë ¨ìš©ì—ì„œ ë¶„í• 
            train_data_path = NEW_FEATURES_DATA_PATH
            validation_data_path = None  # í›ˆë ¨ìš©ì—ì„œ ë¶„í• 
            priority_level = 2
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ)")
            print("  - ìš°ì„ ìˆœìœ„ 2 íŠ¹ì„± ì‚¬ìš© (ì„±ëŠ¥ê³¼ í•´ì„ì˜ ê· í˜•)")
            print("  - ê²€ì¦ìš© ë°ì´í„°ëŠ” í›ˆë ¨ìš©ì—ì„œ ë¶„í• ")
            
        elif model_type == "tabnet":
            # TabNet: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 3 (ìµœëŒ€ ì„±ëŠ¥)
            train_data_path = NEW_FEATURES_DATA_PATH
            validation_data_path = None  # í›ˆë ¨ìš©ì—ì„œ ë¶„í• 
            priority_level = 3
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ìµœëŒ€ ì„±ëŠ¥)")
            print("  - ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„± ì‚¬ìš© (ëª¨ë“  ì„ íƒ íŠ¹ì„±)")
            print("  - TabNetì˜ íŠ¹ì„± ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ í™œìš©")
            print("  - ê²€ì¦ìš© ë°ì´í„°ëŠ” í›ˆë ¨ìš©ì—ì„œ ë¶„í• ")
            
        else:  # ensemble
            # ì•™ìƒë¸”: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 3
            train_data_path = NEW_FEATURES_DATA_PATH
            validation_data_path = None  # í›ˆë ¨ìš©ì—ì„œ ë¶„í• 
            priority_level = 3
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ìµœëŒ€ ì„±ëŠ¥)")
            print("  - ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„± ì‚¬ìš© (ëª¨ë“  ì„ íƒ íŠ¹ì„±)")
            print("  - ê²€ì¦ìš© ë°ì´í„°ëŠ” í›ˆë ¨ìš©ì—ì„œ ë¶„í• ")
        
        # í›ˆë ¨ìš© ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not file_exists(train_data_path):
            print(f"âš ï¸ í›ˆë ¨ìš© ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {train_data_path}")
            print("ëŒ€ì²´ ë°ì´í„° íŒŒì¼ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            
            # ëŒ€ì²´ ë°ì´í„° íŒŒì¼ ì‹œë„
            alternative_paths = [
                SCALED_STANDARD_DATA_PATH,
                SCALED_MINMAX_DATA_PATH,
                NEW_FEATURES_DATA_PATH
            ]
            
            train_data_path = None
            for alt_path in alternative_paths:
                if file_exists(alt_path):
                    train_data_path = alt_path
                    validation_data_path = None  # ëŒ€ì²´ ì‹œì—ëŠ” ë¶„í•  ì‚¬ìš©
                    print(f"âœ“ ëŒ€ì²´ í›ˆë ¨ìš© ë°ì´í„° íŒŒì¼ ì‚¬ìš©: {alt_path}")
                    break
            
            if train_data_path is None:
                print("âœ— ì‚¬ìš© ê°€ëŠ¥í•œ í›ˆë ¨ìš© ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("ë¨¼ì € feature_engineering ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                return None
        
        # ê²€ì¦ìš© ë°ì´í„° íŒŒì¼ í™•ì¸ (ìƒˆë¡œìš´ íŠ¹ì„±ì´ ì•„ë‹Œ ê²½ìš°)
        if validation_data_path and not file_exists(validation_data_path):
            print(f"âš ï¸ ê²€ì¦ìš© ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {validation_data_path}")
            print("í›ˆë ¨ìš© ë°ì´í„°ì—ì„œ ë¶„í• í•˜ì—¬ ê²€ì¦ìš© ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            validation_data_path = None
        
        # ë°ì´í„° ë¡œë“œ
        print(f"ğŸ“¥ í›ˆë ¨ìš© ë°ì´í„° ë¡œë“œ: {train_data_path}")
        df_train = pd.read_csv(train_data_path)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        df_train['loan_status_binary'] = df_train['loan_status'].apply(
            lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
        )
        
        # ìš°ì„ ìˆœìœ„ë³„ íŠ¹ì„± ì„ íƒ
        priority_features = self.get_priority_features(priority_level)
        if priority_features is None:
            return None
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± í•„í„°ë§
        available_features = [f for f in priority_features if f in df_train.columns]
        print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
        
        X_train = df_train[available_features]
        y_train = df_train['loan_status_binary']
        
        # ê²€ì¦ìš© ë°ì´í„° ì²˜ë¦¬
        if validation_data_path and file_exists(validation_data_path):
            print(f"ğŸ“¥ ê²€ì¦ìš© ë°ì´í„° ë¡œë“œ: {validation_data_path}")
            df_validation = pd.read_csv(validation_data_path)
            
            # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
            df_validation['loan_status_binary'] = df_validation['loan_status'].apply(
                lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
            )
            
            X_test = df_validation[available_features]
            y_test = df_validation['loan_status_binary']
            
            print("âœ“ ë³„ë„ ê²€ì¦ìš© ë°ì´í„° ì‚¬ìš©")
        else:
            # í›ˆë ¨ìš© ë°ì´í„°ì—ì„œ ë¶„í• 
            print("âœ“ í›ˆë ¨ìš© ë°ì´í„°ì—ì„œ ê²€ì¦ìš© ë°ì´í„° ë¶„í• ")
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X_train, y_train, test_size=0.2, random_state=self.random_state, stratify=y_train
            )
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        total_missing_train = X_train.isnull().sum().sum()
        total_missing_test = X_test.isnull().sum().sum()
        
        if total_missing_train > 0 or total_missing_test > 0:
            print(f"âš ï¸ ê²½ê³ : í›ˆë ¨ìš© {total_missing_train}ê°œ, ê²€ì¦ìš© {total_missing_test}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("   feature_engineering_step2_scaling.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            return None
        else:
            print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
        
        print(f"âœ“ {model_type} ëª¨ë¸ìš© ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
        print(f"  - ê²€ì¦ ë°ì´í„°: {X_test.shape[0]}ê°œ")
        print(f"  - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ")
        
        return X_train, X_test, y_train, y_test, available_features
    
    def load_basic_data(self):
        """ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
        print("ğŸ“‚ ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì„ íƒëœ íŠ¹ì„± ë¡œë“œ
        if not file_exists(SELECTED_FEATURES_PATH):
            print(f"âœ— ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
            print("ë¨¼ì € feature_selection_analysis.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
            
        selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
        selected_features = selected_features_df['selected_feature'].tolist()
        
        # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ë¡œë“œ
        if not file_exists(SCALED_STANDARD_DATA_PATH):
            print(f"âœ— ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SCALED_STANDARD_DATA_PATH}")
            print("ë¨¼ì € feature_engineering_step2_scaling.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
            
        df = pd.read_csv(SCALED_STANDARD_DATA_PATH)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        df['loan_status_binary'] = df['loan_status'].apply(
            lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
        )
        
        # ì„ íƒëœ íŠ¹ì„±ë§Œ ì‚¬ìš©
        available_features = [f for f in selected_features if f in df.columns]
        print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
        
        X = df[available_features]
        y = df['loan_status_binary']
        
        # ê²°ì¸¡ì¹˜ í™•ì¸ (ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨)
        total_missing = X.isnull().sum().sum()
        if total_missing > 0:
            print(f"âš ï¸ ê²½ê³ : {total_missing}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("   feature_engineering_step2_scaling.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            return None
        else:
            print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
        
        # Train/Test Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state, stratify=y
        )
        
        print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
        print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ")
        print(f"  - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ")
        
        return X_train, X_test, y_train, y_test, available_features
    
    def get_data_info(self, model_type):
        """ë°ì´í„° ì •ë³´ ë°˜í™˜"""
        data = self.load_data_for_model(model_type)
        if data is None:
            return None
        
        X_train, X_test, y_train, y_test, features = data
        
        info = {
            'model_type': model_type,
            'train_samples': X_train.shape[0],
            'test_samples': X_test.shape[0],
            'n_features': X_train.shape[1],
            'feature_names': features,
            'class_distribution_train': {
                'positive': int(y_train.sum()),
                'negative': int(len(y_train) - y_train.sum()),
                'positive_ratio': float(y_train.mean())
            },
            'class_distribution_test': {
                'positive': int(y_test.sum()),
                'negative': int(len(y_test) - y_test.sum()),
                'positive_ratio': float(y_test.mean())
            }
        }
        
        return info 