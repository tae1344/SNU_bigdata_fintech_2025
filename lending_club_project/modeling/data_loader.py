"""
ëª¨ë¸ë³„ ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤
ê° ëª¨ë¸ì— ìµœì í™”ëœ ë°ì´í„°ë¥¼ ì œê³µ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import warnings
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.file_paths import (
    SELECTED_FEATURES_PATH,
    SCALED_STANDARD_DATA_PATH,
    SCALED_MINMAX_DATA_PATH,
    NEW_FEATURES_DATA_PATH,
    ensure_directory_exists,
    file_exists
)
from config.settings import settings

warnings.filterwarnings('ignore')

class ModelDataLoader:
    """ëª¨ë¸ë³„ ìµœì í™”ëœ ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤"""
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        
    def get_priority_features(self, priority_level):
        """ìš°ì„ ìˆœìœ„ì— ë”°ë¼ íŠ¹ì„± ì„ íƒ"""
        print(f"ğŸ“Š ìš°ì„ ìˆœìœ„ {priority_level} íŠ¹ì„± ì„ íƒ ì¤‘...")
        
        if not file_exists(SELECTED_FEATURES_PATH):
            print(f"âœ— ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
            return None
            
        selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
        
        if priority_level == 1:
            # ìš°ì„ ìˆœìœ„ 1: 9ê°œ í•µì‹¬ íŠ¹ì„± (ìµœìš°ì„ )
            priority_features = selected_features_df[
                selected_features_df['priority'] == 1
            ]['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„±: {len(priority_features)}ê°œ")
            
        elif priority_level == 2:
            # ìš°ì„ ìˆœìœ„ 2: 17ê°œ íŠ¹ì„± (1 + 2)
            priority_features = selected_features_df[
                selected_features_df['priority'].isin([1, 2])
            ]['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 2 íŠ¹ì„±: {len(priority_features)}ê°œ")
            
        else:  # priority_level == 3
            # ìš°ì„ ìˆœìœ„ 3: 30ê°œ íŠ¹ì„± (ëª¨ë“  ì„ íƒëœ íŠ¹ì„±)
            priority_features = selected_features_df['selected_feature'].tolist()
            print(f"âœ“ ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„±: {len(priority_features)}ê°œ")
        
        return priority_features
    
    def load_data_for_model(self, model_type):
        """ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“‚ {model_type} ëª¨ë¸ìš© ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ëª¨ë¸ë³„ ë°ì´í„° ì „ëµ ì ìš©
        if model_type == "logistic_regression":
            # ë¡œì§€ìŠ¤í‹± íšŒê·€: StandardScaler + ìš°ì„ ìˆœìœ„ 1
            data_path = SCALED_STANDARD_DATA_PATH
            priority_level = 1
            print("  - StandardScaler ë°ì´í„° ì‚¬ìš© (ì„ í˜• ëª¨ë¸ ìµœì í™”)")
            print("  - ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„± ì‚¬ìš© (í•´ì„ ê°€ëŠ¥ì„± ì¤‘ì‹œ)")
            
        elif model_type == "random_forest":
            # ëœë¤í¬ë ˆìŠ¤íŠ¸: MinMaxScaler + ìš°ì„ ìˆœìœ„ 1
            data_path = SCALED_MINMAX_DATA_PATH
            priority_level = 1
            print("  - MinMaxScaler ë°ì´í„° ì‚¬ìš© (íŠ¸ë¦¬ ëª¨ë¸ ìµœì í™”)")
            print("  - ìš°ì„ ìˆœìœ„ 1 íŠ¹ì„± ì‚¬ìš© (ì•ˆì •ì„± ì¤‘ì‹œ)")
            
        elif model_type in ["xgboost", "lightgbm"]:
            # XGBoost/LightGBM: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 2
            data_path = NEW_FEATURES_DATA_PATH
            priority_level = 2
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ)")
            print("  - ìš°ì„ ìˆœìœ„ 2 íŠ¹ì„± ì‚¬ìš© (ì„±ëŠ¥ê³¼ í•´ì„ì˜ ê· í˜•)")
            
        elif model_type == "tabnet":
            # TabNet: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 3 (ìµœëŒ€ ì„±ëŠ¥)
            data_path = NEW_FEATURES_DATA_PATH
            priority_level = 3
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ìµœëŒ€ ì„±ëŠ¥)")
            print("  - ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„± ì‚¬ìš© (ëª¨ë“  ì„ íƒ íŠ¹ì„±)")
            print("  - TabNetì˜ íŠ¹ì„± ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ í™œìš©")
            
        else:  # ensemble
            # ì•™ìƒë¸”: ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ + ìš°ì„ ìˆœìœ„ 3
            data_path = NEW_FEATURES_DATA_PATH
            priority_level = 3
            print("  - ìƒˆë¡œìš´ íŠ¹ì„± í¬í•¨ ë°ì´í„° ì‚¬ìš© (ìµœëŒ€ ì„±ëŠ¥)")
            print("  - ìš°ì„ ìˆœìœ„ 3 íŠ¹ì„± ì‚¬ìš© (ëª¨ë“  ì„ íƒ íŠ¹ì„±)")
        
        # ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not file_exists(data_path):
            print(f"âœ— ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_path}")
            print("ë¨¼ì € feature_engineering ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        df['loan_status_binary'] = df['loan_status'].apply(
            lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
        )
        
        # ìš°ì„ ìˆœìœ„ë³„ íŠ¹ì„± ì„ íƒ
        priority_features = self.get_priority_features(priority_level)
        if priority_features is None:
            return None
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± í•„í„°ë§
        available_features = [f for f in priority_features if f in df.columns]
        print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
        
        X = df[available_features]
        y = df['loan_status_binary']
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        total_missing = X.isnull().sum().sum()
        if total_missing > 0:
            print(f"âš ï¸ ê²½ê³ : {total_missing}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("   feature_engineering_step2_scaling.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            return None
        else:
            print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
        
        # Train/Test Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state, stratify=y
        )
        
        print(f"âœ“ {model_type} ëª¨ë¸ìš© ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
        print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ")
        print(f"  - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ")
        
        return X_train, X_test, y_train, y_test, available_features
    
    def load_basic_data(self):
        """ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
        print("ğŸ“‚ ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì„ íƒëœ íŠ¹ì„± ë¡œë“œ
        if not file_exists(SELECTED_FEATURES_PATH):
            print(f"âœ— ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
            print("ë¨¼ì € feature_selection_analysis.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
            
        selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
        selected_features = selected_features_df['selected_feature'].tolist()
        
        # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ë¡œë“œ
        if not file_exists(SCALED_STANDARD_DATA_PATH):
            print(f"âœ— ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SCALED_STANDARD_DATA_PATH}")
            print("ë¨¼ì € feature_engineering_step2_scaling.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
            
        df = pd.read_csv(SCALED_STANDARD_DATA_PATH)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        df['loan_status_binary'] = df['loan_status'].apply(
            lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
        )
        
        # ì„ íƒëœ íŠ¹ì„±ë§Œ ì‚¬ìš©
        available_features = [f for f in selected_features if f in df.columns]
        print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
        
        X = df[available_features]
        y = df['loan_status_binary']
        
        # ê²°ì¸¡ì¹˜ í™•ì¸ (ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨)
        total_missing = X.isnull().sum().sum()
        if total_missing > 0:
            print(f"âš ï¸ ê²½ê³ : {total_missing}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("   feature_engineering_step2_scaling.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            return None
        else:
            print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
        
        # Train/Test Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state, stratify=y
        )
        
        print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
        print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ")
        print(f"  - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ")
        
        return X_train, X_test, y_train, y_test, available_features
    
    def get_data_info(self, model_type):
        """ë°ì´í„° ì •ë³´ ë°˜í™˜"""
        data = self.load_data_for_model(model_type)
        if data is None:
            return None
        
        X_train, X_test, y_train, y_test, features = data
        
        info = {
            'model_type': model_type,
            'train_samples': X_train.shape[0],
            'test_samples': X_test.shape[0],
            'n_features': X_train.shape[1],
            'feature_names': features,
            'class_distribution_train': {
                'positive': int(y_train.sum()),
                'negative': int(len(y_train) - y_train.sum()),
                'positive_ratio': float(y_train.mean())
            },
            'class_distribution_test': {
                'positive': int(y_test.sum()),
                'negative': int(len(y_test) - y_test.sum()),
                'positive_ratio': float(y_test.mean())
            }
        }
        
        return info 