#!/usr/bin/env python3
"""
ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ë° ë°ì´í„° ë¶„í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTEENN, SMOTETomek
import warnings
import sys
import os
from pathlib import Path
import pickle

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config.file_paths import (
    SCALED_STANDARD_DATA_PATH,
    SCALED_MINMAX_DATA_PATH,
    VALIDATION_SCALED_STANDARD_DATA_PATH,
    VALIDATION_SCALED_MINMAX_DATA_PATH,
    NEW_FEATURES_DATA_PATH,
    SELECTED_FEATURES_PATH,
    ensure_directory_exists,
    file_exists
)
from config.settings import settings

warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class DataPreprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ - í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ë° ë°ì´í„° ë¶„í• """
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.preprocessed_data = {}
        self.balancing_methods = {
            'none': 'ì›ë³¸ ë°ì´í„° (ë¶ˆê· í˜• ìœ ì§€)',
            'smote': 'SMOTE (Synthetic Minority Over-sampling Technique)',
            'adasyn': 'ADASYN (Adaptive Synthetic Sampling)',
            'random_under': 'Random Under-sampling',
            'smoteenn': 'SMOTE + ENN (Edited Nearest Neighbors)',
            'smotetomek': 'SMOTE + Tomek Links'
        }
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì„ íƒëœ íŠ¹ì„± ë¡œë“œ
        if not file_exists(SELECTED_FEATURES_PATH):
            print(f"âš ï¸ ì„ íƒëœ íŠ¹ì„± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_FEATURES_PATH}")
            print("ê¸°ë³¸ íŠ¹ì„± ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            selected_features = [
                'loan_amnt', 'int_rate', 'installment', 'dti', 'term_months',
                'fico_avg', 'delinq_2yrs', 'inq_last_6mths', 'revol_util',
                'open_acc', 'pub_rec', 'revol_bal', 'total_acc',
                'annual_inc', 'emp_length_numeric', 'purpose', 'home_ownership'
            ]
        else:
            selected_features_df = pd.read_csv(SELECTED_FEATURES_PATH)
            selected_features = selected_features_df['selected_feature'].tolist()
        
        # í›ˆë ¨ìš© ë°ì´í„° ë¡œë“œ
        if file_exists(SCALED_STANDARD_DATA_PATH):
            print("ğŸ“¥ í›ˆë ¨ìš© Standard Scaled ë°ì´í„° ë¡œë“œ...")
            df_train = pd.read_csv(SCALED_STANDARD_DATA_PATH)
            df_train['loan_status_binary'] = df_train['loan_status'].apply(
                lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
            )
            
            # ê²€ì¦ìš© ë°ì´í„° ë¡œë“œ
            if file_exists(VALIDATION_SCALED_STANDARD_DATA_PATH):
                print("ğŸ“¥ ê²€ì¦ìš© Standard Scaled ë°ì´í„° ë¡œë“œ...")
                df_val = pd.read_csv(VALIDATION_SCALED_STANDARD_DATA_PATH)
                df_val['loan_status_binary'] = df_val['loan_status'].apply(
                    lambda x: 1 if x in ['Default', 'Charged Off', 'Late (31-120 days)', 'Late (16-30 days)'] else 0
                )
            else:
                print("âš ï¸ ê²€ì¦ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í›ˆë ¨ìš©ì—ì„œ ë¶„í• í•©ë‹ˆë‹¤.")
                df_val = None
        else:
            print("âŒ í›ˆë ¨ìš© ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± í•„í„°ë§
        available_features = [f for f in selected_features if f in df_train.columns]
        print(f"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ")
        
        # ë°ì´í„° ë¶„í• 
        X_train = df_train[available_features]
        y_train = df_train['loan_status_binary']
        
        if df_val is not None:
            X_val = df_val[available_features]
            y_val = df_val['loan_status_binary']
        else:
            # í›ˆë ¨ìš©ì—ì„œ ê²€ì¦ìš© ë¶„í• 
            X_train, X_val, y_train, y_val = train_test_split(
                X_train, y_train, test_size=0.2, 
                random_state=self.random_state, stratify=y_train
            )
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        total_missing_train = X_train.isnull().sum().sum()
        total_missing_val = X_val.isnull().sum().sum()
        
        if total_missing_train > 0 or total_missing_val > 0:
            print(f"âš ï¸ ê²½ê³ : í›ˆë ¨ìš© {total_missing_train}ê°œ, ê²€ì¦ìš© {total_missing_val}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return None
        else:
            print("âœ“ ê²°ì¸¡ì¹˜ ì—†ìŒ - ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©")
        
        print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
        print(f"  - ê²€ì¦ ë°ì´í„°: {X_val.shape[0]}ê°œ")
        print(f"  - íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ")
        
        return X_train, X_val, y_train, y_val, available_features
    
    def analyze_class_imbalance(self, y_train, y_val):
        """í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„"""
        print("\nğŸ“Š í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„")
        print("=" * 50)
        
        # í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬
        train_counts = y_train.value_counts()
        train_ratio = train_counts[1] / len(y_train)
        
        print(f"í›ˆë ¨ ë°ì´í„°:")
        print(f"  - ì „ì²´: {len(y_train):,}ê°œ")
        print(f"  - ì •ìƒ (0): {train_counts[0]:,}ê°œ ({train_counts[0]/len(y_train)*100:.1f}%)")
        print(f"  - ë¶€ë„ (1): {train_counts[1]:,}ê°œ ({train_counts[1]/len(y_train)*100:.1f}%)")
        print(f"  - ë¶€ë„ìœ¨: {train_ratio:.3f}")
        
        # ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬
        val_counts = y_val.value_counts()
        val_ratio = val_counts[1] / len(y_val)
        
        print(f"\nê²€ì¦ ë°ì´í„°:")
        print(f"  - ì „ì²´: {len(y_val):,}ê°œ")
        print(f"  - ì •ìƒ (0): {val_counts[0]:,}ê°œ ({val_counts[0]/len(y_val)*100:.1f}%)")
        print(f"  - ë¶€ë„ (1): {val_counts[1]:,}ê°œ ({val_counts[1]/len(y_val)*100:.1f}%)")
        print(f"  - ë¶€ë„ìœ¨: {val_ratio:.3f}")
        
        # ë¶ˆê· í˜• ì •ë„ í‰ê°€
        if train_ratio < 0.1:
            print(f"\nâš ï¸ ì‹¬ê°í•œ ë¶ˆê· í˜• (ë¶€ë„ìœ¨ < 10%)")
        elif train_ratio < 0.2:
            print(f"\nâš ï¸ ì¤‘ê°„ ë¶ˆê· í˜• (ë¶€ë„ìœ¨ 10-20%)")
        else:
            print(f"\nâœ“ ë¹„êµì  ê· í˜•ì¡íŒ ë°ì´í„° (ë¶€ë„ìœ¨ > 20%)")
        
        return train_ratio, val_ratio
    
    def apply_balancing_method(self, X_train, y_train, method='smote'):
        """í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ë°©ë²• ì ìš©"""
        print(f"\nğŸ”„ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ì ìš©: {self.balancing_methods[method]}")
        print("=" * 50)
        
        if method == 'none':
            print("âœ“ ì›ë³¸ ë°ì´í„° ìœ ì§€ (ë¶ˆê· í˜• ì¡°ì • ì—†ìŒ)")
            return X_train, y_train
        
        try:
            if method == 'smote':
                balancer = SMOTE(random_state=self.random_state)
            elif method == 'adasyn':
                balancer = ADASYN(random_state=self.random_state)
            elif method == 'random_under':
                balancer = RandomUnderSampler(random_state=self.random_state)
            elif method == 'smoteenn':
                balancer = SMOTEENN(random_state=self.random_state)
            elif method == 'smotetomek':
                balancer = SMOTETomek(random_state=self.random_state)
            else:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")
                return X_train, y_train
            
            # ë¶ˆê· í˜• ì¡°ì • ì ìš©
            X_balanced, y_balanced = balancer.fit_resample(X_train, y_train)
            
            # ê²°ê³¼ í™•ì¸
            original_counts = y_train.value_counts()
            balanced_counts = y_balanced.value_counts()
            
            print(f"ì¡°ì • ì „:")
            print(f"  - ì •ìƒ: {original_counts[0]:,}ê°œ")
            print(f"  - ë¶€ë„: {original_counts[1]:,}ê°œ")
            print(f"  - ë¹„ìœ¨: {original_counts[1]/len(y_train)*100:.1f}%")
            
            print(f"\nì¡°ì • í›„:")
            print(f"  - ì •ìƒ: {balanced_counts[0]:,}ê°œ")
            print(f"  - ë¶€ë„: {balanced_counts[1]:,}ê°œ")
            print(f"  - ë¹„ìœ¨: {balanced_counts[1]/len(y_balanced)*100:.1f}%")
            
            print(f"\nâœ“ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ì™„ë£Œ")
            print(f"  - ìƒ˜í”Œ ìˆ˜ ë³€í™”: {len(y_train):,} â†’ {len(y_balanced):,}")
            
            return X_balanced, y_balanced
            
        except Exception as e:
            print(f"âŒ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ì›ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return X_train, y_train
    
    def save_preprocessed_data(self, X_train, X_val, y_train, y_val, method='smote'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        print(f"\nğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        preprocessed_dir = Path(__file__).parent / "preprocessed_data"
        preprocessed_dir.mkdir(exist_ok=True)
        
        # ë°ì´í„° ì €ì¥
        data_dict = {
            'X_train': X_train,
            'X_val': X_val,
            'y_train': y_train,
            'y_val': y_val,
            'method': method,
            'timestamp': pd.Timestamp.now()
        }
        
        # CSV íŒŒì¼ë¡œ ì €ì¥
        train_data = pd.concat([X_train, y_train], axis=1)
        val_data = pd.concat([X_val, y_val], axis=1)
        
        train_file = preprocessed_dir / f"train_balanced_{method}.csv"
        val_file = preprocessed_dir / f"val_balanced_{method}.csv"
        
        train_data.to_csv(train_file, index=False)
        val_data.to_csv(val_file, index=False)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        meta_data = {
            'method': method,
            'train_samples': len(X_train),
            'val_samples': len(X_val),
            'features': X_train.shape[1],
            'train_positive_ratio': y_train.mean(),
            'val_positive_ratio': y_val.mean(),
            'timestamp': str(pd.Timestamp.now())
        }
        
        meta_file = preprocessed_dir / f"metadata_{method}.json"
        with open(meta_file, 'w') as f:
            import json
            json.dump(meta_data, f, indent=2)
        
        print(f"âœ“ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {train_file}")
        print(f"  - ê²€ì¦ ë°ì´í„°: {val_file}")
        print(f"  - ë©”íƒ€ë°ì´í„°: {meta_file}")
        
        return train_file, val_file, meta_file
    
    def visualize_balancing_results(self, y_original, y_balanced, method='smote'):
        """ë¶ˆê· í˜• ì¡°ì • ê²°ê³¼ ì‹œê°í™”"""
        print(f"\nğŸ“Š ë¶ˆê· í˜• ì¡°ì • ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        reports_dir = Path(__file__).parent.parent / "reports-final"
        reports_dir.mkdir(exist_ok=True)
        
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # ì¡°ì • ì „
        original_counts = y_original.value_counts()
        axes[0].bar(['ì •ìƒ', 'ë¶€ë„'], [original_counts[0], original_counts[1]], 
                   color=['lightblue', 'lightcoral'])
        axes[0].set_title('ì¡°ì • ì „ í´ë˜ìŠ¤ ë¶„í¬')
        axes[0].set_ylabel('ìƒ˜í”Œ ìˆ˜')
        for i, v in enumerate([original_counts[0], original_counts[1]]):
            axes[0].text(i, v + max(original_counts) * 0.01, f'{v:,}', 
                        ha='center', va='bottom')
        
        # ì¡°ì • í›„
        balanced_counts = y_balanced.value_counts()
        axes[1].bar(['ì •ìƒ', 'ë¶€ë„'], [balanced_counts[0], balanced_counts[1]], 
                   color=['lightgreen', 'lightcoral'])
        axes[1].set_title('ì¡°ì • í›„ í´ë˜ìŠ¤ ë¶„í¬')
        axes[1].set_ylabel('ìƒ˜í”Œ ìˆ˜')
        for i, v in enumerate([balanced_counts[0], balanced_counts[1]]):
            axes[1].text(i, v + max(balanced_counts) * 0.01, f'{v:,}', 
                        ha='center', va='bottom')
        
        plt.tight_layout()
        
        # íŒŒì¼ ì €ì¥
        output_file = reports_dir / f"class_balancing_{method}.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ ì‹œê°í™” ì €ì¥: {output_file}")
    
    def run_preprocessing(self, balancing_method='smote'):
        """ì „ì²´ ì „ì²˜ë¦¬ ê³¼ì • ì‹¤í–‰"""
        print("ğŸš€ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 80)
        
        # 1. ë°ì´í„° ë¡œë“œ
        data = self.load_data()
        if data is None:
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        X_train, X_val, y_train, y_val, features = data
        
        # 2. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„
        train_ratio, val_ratio = self.analyze_class_imbalance(y_train, y_val)
        
        # 3. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì •
        X_train_balanced, y_train_balanced = self.apply_balancing_method(
            X_train, y_train, balancing_method
        )
        
        # 4. ê²°ê³¼ ì‹œê°í™”
        self.visualize_balancing_results(y_train, y_train_balanced, balancing_method)
        
        # 5. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        train_file, val_file, meta_file = self.save_preprocessed_data(
            X_train_balanced, X_val, y_train_balanced, y_val, balancing_method
        )
        
        print(f"\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ë¬¼:")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {train_file}")
        print(f"  - ê²€ì¦ ë°ì´í„°: {val_file}")
        print(f"  - ë©”íƒ€ë°ì´í„°: {meta_file}")
        print(f"  - ì‹œê°í™”: reports-final/class_balancing_{balancing_method}.png")
        
        return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë°ì´í„° ì „ì²˜ë¦¬ - í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì •')
    parser.add_argument('--method', type=str, default='random_under',
                       choices=['none', 'smote', 'adasyn', 'random_under', 'smoteenn', 'smotetomek'],
                       help='í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¡°ì • ë°©ë²•')
    
    args = parser.parse_args()
    
    preprocessor = DataPreprocessor()
    success = preprocessor.run_preprocessing(args.method)
    
    if success:
        print("\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ì„±ê³µ!")
        sys.exit(0)
    else:
        print("\nâŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨!")
        sys.exit(1)

if __name__ == "__main__":
    main() 