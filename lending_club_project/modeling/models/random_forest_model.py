"""
ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í´ë˜ìŠ¤
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from .base_model import BaseModel

class RandomForestModel(BaseModel):
    """ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, random_state=42, **kwargs):
        super().__init__(random_state)
        self.model_params = {
            'n_estimators': 100,
            'max_depth': 10,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'random_state': self.random_state,
            'class_weight': 'balanced',
            'n_jobs': -1,
            **kwargs
        }
    
    def train(self, X_train, y_train, X_test, y_test):
        """ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨"""
        print("ğŸŒ² ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        # ëª¨ë¸ ì •ì˜
        self.model = RandomForestClassifier(**self.model_params)
        
        # ëª¨ë¸ í›ˆë ¨
        self.model.fit(X_train, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        results = self.evaluate(X_test, y_test)
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
        self.feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"âœ“ ëœë¤í¬ë ˆìŠ¤íŠ¸ í›ˆë ¨ ì™„ë£Œ")
        print(f"  - ì •í™•ë„: {results['accuracy']:.4f}")
        print(f"  - AUC: {results['auc']:.4f}")
        
        return self.model
    
    def get_feature_importance(self, feature_names=None):
        """íŠ¹ì„± ì¤‘ìš”ë„ ë°˜í™˜"""
        if self.feature_importance is None:
            return None
        return self.feature_importance
    
    def get_tree_info(self):
        """íŠ¸ë¦¬ ì •ë³´ ë°˜í™˜"""
        if self.model is None:
            return None
        
        return {
            'n_trees': self.model.n_estimators,
            'n_features': self.model.n_features_in_,
            'max_depth': self.model.max_depth,
            'min_samples_split': self.model.min_samples_split,
            'min_samples_leaf': self.model.min_samples_leaf,
            'feature_names': self.model.feature_names_in_.tolist()
        }
    
    def get_model_summary(self):
        """ëª¨ë¸ ìš”ì•½ ì •ë³´"""
        if self.model is None:
            return "ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        summary = {
            'model_type': 'Random Forest',
            'parameters': self.model_params,
            'n_trees': self.model.n_estimators,
            'n_features': self.model.n_features_in_,
            'classes': self.model.classes_.tolist()
        }
        
        if self.results:
            summary.update({
                'accuracy': self.results['accuracy'],
                'auc': self.results['auc']
            })
        
        return summary
    
    def get_individual_tree_predictions(self, X, n_trees=10):
        """ê°œë³„ íŠ¸ë¦¬ë“¤ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜ (ë””ë²„ê¹…ìš©)"""
        if self.model is None:
            return None
        
        predictions = []
        for i in range(min(n_trees, self.model.n_estimators)):
            tree_pred = self.model.estimators_[i].predict(X)
            predictions.append(tree_pred)
        
        return np.array(predictions) 